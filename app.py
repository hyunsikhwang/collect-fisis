import streamlit as st
import aiohttp
import asyncio
import pandas as pd
import nest_asyncio
import json
import time
import duckdb
import os
import requests
from datetime import datetime
from pytz import timezone
from streamlit_echarts import st_pyecharts
from pyecharts import options as opts
from pyecharts.charts import Line, Bar
from pyecharts.commons.utils import JsCode

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë³´í—˜ì‚¬ ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨ ìˆ˜ì§‘ê¸°",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ë¹„ë™ê¸° ë£¨í”„ ì¶©ëŒ ë°©ì§€
nest_asyncio.apply()

# ==========================================
# 1. ìƒìˆ˜ ë° ê¸°ë³¸ ì„¤ì •
# ==========================================
# API í‚¤ (st.secrets ì²˜ë¦¬ í›„ í•„ìš”ì‹œ UIì—ì„œ ì…ë ¥)
API_KEY = st.secrets.get("FSS_API_KEY", "")
TARGET_MONTH = "202509" # ê¸°ë³¸ê°’ ì„¤ì •

TERM = "Q" # ë¶„ê¸°
BASE_URL = "http://fisis.fss.or.kr/openapi"
MAX_CONCURRENT_REQUESTS = 20

# ==========================================
# 1.5. MotherDuck DB ì„¤ì •
# ==========================================
MD_TOKEN = st.secrets.get("MOTHERDUCK_TOKEN", "")
DB_NAME = "fisis_cache"
TABLE_NAME = "insurance_stats"
COLUMNS = ['êµ¬ë¶„', 'íšŒì‚¬ì½”ë“œ', 'íšŒì‚¬ëª…', 'ê³„ì •ì½”ë“œ', 'ê³„ì •ëª…', 'ê¸°ì¤€ë…„ì›”', 'ë‹¨ìœ„', 'ê°’']

def get_md_connection():
    """MotherDuck ì—°ê²° ì„¤ì •"""
    if not MD_TOKEN:
        return None
    try:
        # MotherDuck ì—°ê²° (md: ë’¤ì— í† í°ì´ ì—†ìœ¼ë©´ st.secretsì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ í™•ì¸)
        conn = duckdb.connect(f"md:?motherduck_token={MD_TOKEN}")
        # ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ë° ì‚¬ìš©
        conn.execute(f"CREATE DATABASE IF NOT EXISTS {DB_NAME}")
        conn.execute(f"USE {DB_NAME}")
        # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±
        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {TABLE_NAME} (
                êµ¬ë¶„ VARCHAR,
                íšŒì‚¬ì½”ë“œ VARCHAR,
                íšŒì‚¬ëª… VARCHAR,
                ê³„ì •ì½”ë“œ VARCHAR,
                ê³„ì •ëª… VARCHAR,
                ê¸°ì¤€ë…„ì›” VARCHAR,
                ë‹¨ìœ„ VARCHAR,
                ê°’ DOUBLE,
                ìˆ˜ì§‘ì¼ì‹œ TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        return conn
    except Exception as e:
        st.error(f"MotherDuck ì—°ê²° ì˜¤ë¥˜: {e}")
        return None

def get_cached_data(target_month):
    """MotherDuckì—ì„œ ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ"""
    conn = get_md_connection()
    if conn:
        try:
            df = conn.execute(f"SELECT * FROM {TABLE_NAME} WHERE ê¸°ì¤€ë…„ì›” = ?", [target_month]).df()
            conn.close()
            return df
        except Exception as e:
            st.warning(f"ë°ì´í„° ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

def save_to_md(df):
    """ë°ì´í„°ë¥¼ MotherDuckì— ì €ì¥"""
    if df.empty:
        return
    conn = get_md_connection()
    if conn:
        try:
            # ì»¬ëŸ¼ ìˆœì„œ ê³ ì • ë° ë°ì´í„° í´ë¦¬ë‹
            df_to_save = df[COLUMNS].copy()
            for col in ['íšŒì‚¬ì½”ë“œ', 'ê³„ì •ì½”ë“œ', 'ê¸°ì¤€ë…„ì›”']:
                df_to_save[col] = df_to_save[col].astype(str).str.strip()

            # ì„ì‹œ ë·°ë¥¼ ìƒì„±í•˜ì—¬ ë°ì´í„°ë¥¼ ì ì¬
            conn.register("df_to_save", df_to_save)
            # ëª…ì‹œì ìœ¼ë¡œ ì»¬ëŸ¼ì„ ì§€ì •í•˜ì—¬ INSERT (ìˆœì„œ ì¼ê´€ì„± ë³´ì¥)
            col_names = ", ".join(COLUMNS) + ", ìˆ˜ì§‘ì¼ì‹œ"
            conn.execute(f"INSERT INTO {TABLE_NAME} ({col_names}) SELECT *, CURRENT_TIMESTAMP FROM df_to_save")
            conn.close()
        except Exception as e:
            st.error(f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

def load_kics_analysis_data():
    """K-ICS ë¶„ì„ì„ ìœ„í•œ ì „ì²´ ë°ì´í„° ë¡œë“œ ë° ê³„ì‚°"""
    conn = get_md_connection()
    if not conn:
        return pd.DataFrame()
    
    try:
        # ê´€ì‹¬ ìˆëŠ” ê³„ì •ë“¤ë§Œ í•„í„°ë§í•´ì„œ ê°€ì ¸ì˜¤ê¸°
        target_accounts = [
            'ì§€ê¸‰ì—¬ë ¥ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© ì „)', 
            'ì§€ê¸‰ì—¬ë ¥ê¸°ì¤€ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© ì „)',
            'ì§€ê¸‰ì—¬ë ¥ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© í›„)', 
            'ì§€ê¸‰ì—¬ë ¥ê¸°ì¤€ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© í›„)'
        ]
        
        # [DEBUG] ë””ë²„ê¹… ì˜µì…˜ (Dashboard ìƒë‹¨ì— í‘œì‹œë¨)
        show_debug = st.checkbox("ğŸ” ìƒì„¸ ë°ì´í„° ì¶”ì¶œ ê³¼ì • í™•ì¸ (ë””ë²„ê±°)", value=False)
        
        # 1. DBì— ìˆëŠ” ëª¨ë“  ë…íŠ¹í•œ ê³„ì •ëª… í™•ì¸
        all_accounts = conn.execute(f"SELECT DISTINCT ê³„ì •ëª… FROM {TABLE_NAME}").df()['ê³„ì •ëª…'].tolist()
        if show_debug:
            st.write(f"DEBUG: DB ë‚´ ì´ ê³„ì • ìˆ˜: {len(all_accounts)}")
            st.write(f"DEBUG: DB ë‚´ ê³„ì • ìƒ˜í”Œ: {all_accounts[:5]}")
        
        # 2. ìœ ì‚¬í•œ ê³„ì •ëª… ë§¤í•‘ (ê³µë°± ì œê±° ë° ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰ìœ¼ë¡œ ê°•í™”)
        def find_best_match(target, candidates):
            target_clean = target.replace(" ", "")
            # ì™„ì „ ì¼ì¹˜(ê³µë°± ì œê±°)
            for c in candidates:
                if c.replace(" ", "") == target_clean:
                    return c
            # ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰
            for c in candidates:
                if target_clean in c.replace(" ", "") or c.replace(" ", "") in target_clean:
                    return c
            return target

        actual_targets = [find_best_match(t, all_accounts) for t in target_accounts]
        if show_debug:
            st.write(f"DEBUG: ë§¤í•‘ëœ íƒ€ê²Ÿ ê³„ì •: {actual_targets}")
        
        # IN ì ˆ íŒŒë¼ë¯¸í„° ìƒì„±
        placeholders = ', '.join(['?' for _ in actual_targets])
        query = f"SELECT * FROM {TABLE_NAME} WHERE ê³„ì •ëª… IN ({placeholders})"
        df = conn.execute(query, actual_targets).df()
        conn.close()
        
        if show_debug:
            st.write(f"DEBUG: ì¡°íšŒëœ ë¡œìš° ìˆ˜: {len(df)}")

        if df.empty:
            return pd.DataFrame()

        # ë°ì´í„° í´ë¦¬ë‹
        df['ê¸°ì¤€ë…„ì›”'] = df['ê¸°ì¤€ë…„ì›”'].astype(str).str.strip()
        
        # ë§¤í•‘ìš© ì‚¬ì „ ìƒì„± (ì›ë˜ ì´ë¦„ìœ¼ë¡œ í†µì¼)
        name_map = dict(zip(actual_targets, target_accounts))
        df['ê³„ì •ëª…'] = df['ê³„ì •ëª…'].map(name_map)
        
        if show_debug:
            st.write("DEBUG: ê³„ì •ëª… ë§¤í•‘ í›„ ë°ì´í„° ìƒ˜í”Œ:", df.head())

        # í”¼ë²—í•˜ì—¬ ê³„ì‚°í•˜ê¸° ì‰½ê²Œ ë³€í™˜
        # ê³„ì •ëª…ì´ ì¤‘ë³µë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ (ë™ì¼ íšŒì‚¬ê°€ ê°™ì€ ë‹¬ì— ì—¬ëŸ¬ë²ˆ ìˆ˜ì§‘ëœ ê²½ìš° ë“±) sumìœ¼ë¡œ ì§‘ê³„
        pdf = df.pivot_table(
            index=['êµ¬ë¶„', 'ê¸°ì¤€ë…„ì›”', 'íšŒì‚¬ëª…'],
            columns='ê³„ì •ëª…',
            values='ê°’',
            aggfunc='sum'
        ).reset_index()
        
        if show_debug:
            st.write("DEBUG: í”¼ë²— í›„ ë°ì´í„° ì»¬ëŸ¼:", pdf.columns.tolist())
            st.write("DEBUG: í”¼ë²— í›„ ë°ì´í„° ìˆ˜:", len(pdf))
        # í•„ìš”í•œ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸ (ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€)
        for col in target_accounts:
            if col not in pdf.columns:
                pdf[col] = 0

        # ê·¸ë£¹ë³„ í•©ê³„ ê³„ì‚° (ìƒëª…ë³´í—˜, ì†í•´ë³´í—˜, ì „ì²´)
        # 1. ìƒëª…/ì†í•´ë³„ í•©ê³„
        grouped = pdf.groupby(['êµ¬ë¶„', 'ê¸°ì¤€ë…„ì›”'])[target_accounts].sum().reset_index()
        
        # 2. ì „ì²´(Total) í•©ê³„ ìƒì„±
        total = pdf.groupby(['ê¸°ì¤€ë…„ì›”'])[target_accounts].sum().reset_index()
        total['êµ¬ë¶„'] = 'ì „ì²´'
        
        # ê²°í•©
        final_df = pd.concat([grouped, total], ignore_index=True)
        
        # K-ICS ë¹„ìœ¨ ê³„ì‚° (%)
        # ê²½ê³¼ì¡°ì¹˜ ì „
        final_df['ratio_before'] = (final_df['ì§€ê¸‰ì—¬ë ¥ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© ì „)'] / 
                                    final_df['ì§€ê¸‰ì—¬ë ¥ê¸°ì¤€ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© ì „)'].replace(0, pd.NA)) * 100
        # ê²½ê³¼ì¡°ì¹˜ í›„
        final_df['ratio_after'] = (final_df['ì§€ê¸‰ì—¬ë ¥ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© í›„)'] / 
                                   final_df['ì§€ê¸‰ì—¬ë ¥ê¸°ì¤€ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© í›„)'].replace(0, pd.NA)) * 100
        
        # ì •ë ¬ (ë‚ ì§œìˆœ)
        final_df = final_df.sort_values('ê¸°ì¤€ë…„ì›”')
        
        return final_df
    except Exception as e:
        st.error(f"ë¶„ì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def fetch_ecos_bond_yield(start_month, end_month):
    """ECOSì—ì„œ êµ­ê³ ì±„ 10ë…„ ê¸ˆë¦¬ ì¡°íšŒ"""
    ECOS_API_KEY = st.secrets.get("ECOS_API_KEY", "")
    if not ECOS_API_KEY:
        return pd.DataFrame()
    
    # K-ICS ë°ì´í„° ë²”ìœ„ì— ë§ì¶° ì‹œì‘/ì¢…ë£Œì¼ ì„¤ì •
    # start_month/end_month: '202303' í˜•ì‹ -> '20230301' / '20230331' ë“±ìœ¼ë¡œ ë³€í™˜ í•„ìš”í•˜ë‚˜
    # ECOSëŠ” ë‹¨ìˆœíˆ ì•ë’¤ ë‚ ì§œë§Œ ë„‰ë„‰íˆ ì£¼ë©´ ë¨
    start_date = f"{start_month}01"
    # í˜„ì¬ ë‚ ì§œ ê¸°ì¤€
    KST = timezone('Asia/Seoul')
    nowSeo = datetime.now(KST).strftime('%Y%m%d')
    
    bond_cd = '010210000' # êµ­ê³ ì±„ 10ë…„
    url = f'http://ecos.bok.or.kr/api/StatisticSearch/{ECOS_API_KEY}/json/kr/1/10000/817Y002/D/{start_date}/{nowSeo}/{bond_cd}'

    try:
        res = requests.get(url, timeout=10)
        data = res.json()
        if 'StatisticSearch' in data and 'row' in data['StatisticSearch']:
            rows = data['StatisticSearch']['row']
            df = pd.DataFrame(rows)
            df['yield'] = df['DATA_VALUE'].astype(float)
            # TIME: 20230301 -> ê¸°ì¤€ë…„ì›” 202303 ì¶”ì¶œ
            df['ê¸°ì¤€ë…„ì›”'] = df['TIME'].str[:6]
            
            # ì›”ë³„ ë§ˆì§€ë§‰ ì˜ì—…ì¼ ê¸°ì¤€ ê¸ˆë¦¬ ì¶”ì¶œ (K-ICS ëŒ€ë¹„ìš©)
            df_monthly = df.groupby('ê¸°ì¤€ë…„ì›”').last().reset_index()[['ê¸°ì¤€ë…„ì›”', 'yield']]
            return df_monthly
    except Exception as e:
        st.warning(f"ECOS ê¸ˆë¦¬ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    return pd.DataFrame()

def shorten_company_name(name):
    """íšŒì‚¬ëª…ì„ ë³´ê¸° ì¢‹ê²Œ ì¶•ì•½ (ì£¼ì‹íšŒì‚¬, (ì£¼), í•œêµ­ì§€ì  ë“± ì œê±°)"""
    if not name:
        return ""
    
    # ì œê±°í•  ë‹¨ì–´ ëª©ë¡
    removals = [
        "ì£¼ì‹íšŒì‚¬", "(ì£¼)", "ì£¼", 
        "ìƒëª…ë³´í—˜", "ì†í•´ë³´í—˜", "í™”ì¬í•´ìƒë³´í—˜", "í™”ì¬ë³´í—˜", "í•´ìƒë³´í—˜",
        "í•œêµ­ì§€ì "
    ]
    
    short_name = name
    for r in removals:
        short_name = short_name.replace(r, "")
    
    return short_name.strip()

def render_sector_chart(sector, filtered_df, company_df, color_sets, weighted_avg):
    """íŠ¹ì • ì—…ê¶Œì˜ ëˆ„ì  ë°” ì°¨íŠ¸ ë° í‰ê· ì„ ì„ ë Œë”ë§"""
    import pandas as pd
    from pyecharts import options as opts
    from pyecharts.charts import Bar
    from pyecharts.commons.utils import JsCode
    from streamlit_echarts import st_pyecharts

    st.write(f"### {sector}")
    
    # í•´ë‹¹ ì—…ê¶Œ ë°ì´í„° í•„í„°ë§ ë° ì •ë ¬
    s_df = filtered_df[filtered_df['êµ¬ë¶„'] == sector].sort_values('final_ratio', ascending=False)
    
    if s_df.empty:
        st.info(f"{sector} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ëˆ„ì  ì°¨íŠ¸ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
    base_ratios = [] # í•˜ë‹¨ (A)
    effect_ratios = [] # ìƒë‹¨ (D-A)
    total_ratios = [] # ë ˆì´ë¸” í‘œì‹œìš© (D)
    
    for _, row in s_df.iterrows():
        a_val = float(row['A'])
        d_val = float(row['final_ratio'])
        
        if row['is_fallback']:
            base_ratios.append(int(round(a_val, 0)))
            effect_ratios.append(0)
        else:
            base_ratios.append(int(round(a_val, 0)))
            effect_ratios.append(max(0, int(round(d_val - a_val, 0))))
        
        total_ratios.append(int(round(d_val, 0)))

    bar = Bar(init_opts=opts.InitOpts(width="100%", height="500px", theme="white", renderer="svg"))
    bar.add_xaxis(xaxis_data=s_df['short_display_name'].tolist())
    
    # 1. í•˜ë‹¨ ë°”: ê²½ê³¼ì¡°ì¹˜ ì „
    bar.add_yaxis(
        series_name="ê²½ê³¼ì¡°ì¹˜ ì „",
        y_axis=base_ratios,
        stack="stack1",
        label_opts=opts.LabelOpts(is_show=False),
        itemstyle_opts=opts.ItemStyleOpts(color=color_sets[sector][0])
    )
    
    # 2. ìƒë‹¨ ë°”: ê²½ê³¼ì¡°ì¹˜ íš¨ê³¼
    bar.add_yaxis(
        series_name="ê²½ê³¼ì¡°ì¹˜ íš¨ê³¼",
        y_axis=effect_ratios,
        stack="stack1",
        label_opts=opts.LabelOpts(
            is_show=True, 
            position="top", 
            formatter=JsCode("""function(params) {
                var total_ratios = """ + str(total_ratios) + """;
                return total_ratios[params.dataIndex] + '%';
            }""")
        ),
        itemstyle_opts=opts.ItemStyleOpts(color=color_sets[sector][1]),
        markline_opts=opts.MarkLineOpts(
            data=[{"yAxis": round(weighted_avg, 2), "name": f"ì—…ê¶Œ í‰ê·  ({round(weighted_avg, 1)}%)"}],
            label_opts=opts.LabelOpts(formatter=f"{sector} í‰ê· : {round(weighted_avg, 1)}%", position="insideEndTop"),
            linestyle_opts=opts.LineStyleOpts(type_="dashed", width=1, color="#D10000")
        )
    )
    
    bar.set_global_opts(
        title_opts=opts.TitleOpts(title=f"{sector}ì‚¬ë³„ K-ICS ë¹„ìœ¨"),
        xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=45, interval=0, font_size=11)),
        yaxis_opts=opts.AxisOpts(name="ë¹„ìœ¨ (%)", axislabel_opts=opts.LabelOpts(formatter="{value}%")),
        tooltip_opts=opts.TooltipOpts(
            trigger="axis", 
            axis_pointer_type="shadow",
            formatter=JsCode("""function(params) {
                var res = params[0].name + '<br/>';
                var total = 0;
                for(var i=0; i<params.length; i++) {
                    res += params[i].marker + params[i].seriesName + ': ' + params[i].value + '%<br/>';
                    total += params[i].value;
                }
                res += '<b>ìµœì¢… ë¹„ìœ¨ (ê²½ê³¼í›„): ' + total + '%</b>';
                return res;
            }""")
        ),
    )
    
    st_pyecharts(bar, height="500px", key=f"bar_{sector}")

def get_available_months():
    """DBì— ì €ì¥ëœ ëª¨ë“  ê¸°ì¤€ë…„ì›” ëª©ë¡ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ë°˜í™˜"""
    conn = get_md_connection()
    if not conn:
        return []
    try:
        # ìµœì‹ ìˆœ ì •ë ¬
        df = conn.execute(f"SELECT DISTINCT ê¸°ì¤€ë…„ì›” FROM {TABLE_NAME} ORDER BY ê¸°ì¤€ë…„ì›” DESC").df()
        conn.close()
        return df['ê¸°ì¤€ë…„ì›”'].tolist()
    except Exception as e:
        st.error(f"ê¸°ì¤€ë…„ì›” ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

def load_company_solvency_data(target_month):
    """ë³´í—˜ì‚¬ë³„ íŠ¹ì • ê¸°ì¤€ë…„ì›” ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    if not target_month:
        return pd.DataFrame(), ""

    conn = get_md_connection()
    if not conn:
        return pd.DataFrame(), target_month
    
    try:
        # 1. í•„ìš”í•œ ê³„ì •ì½”ë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        # A, B, C, D, E, F (E, FëŠ” ê°€ì¤‘í‰ê·  ê³„ì‚°ìš© ë¶„ì/ë¶„ëª¨, B, CëŠ” Fallbackìš©)
        query = f"""
            SELECT êµ¬ë¶„, íšŒì‚¬ëª…, ê³„ì •ì½”ë“œ, ê°’, ê¸°ì¤€ë…„ì›”
            FROM {TABLE_NAME}
            WHERE ê¸°ì¤€ë…„ì›” = ? AND ê³„ì •ì½”ë“œ IN ('A', 'B', 'C', 'D', 'E', 'F')
        """
        df = conn.execute(query, [target_month]).df()
        conn.close()

        if df.empty:
            return pd.DataFrame(), target_month

        # 3. í”¼ë²—í•˜ì—¬ A, D ì»¬ëŸ¼ìœ¼ë¡œ ë¶„ë¦¬
        pdf = df.pivot_table(
            index=['êµ¬ë¶„', 'íšŒì‚¬ëª…', 'ê¸°ì¤€ë…„ì›”'],
            columns='ê³„ì •ì½”ë“œ',
            values='ê°’',
            aggfunc='first'
        ).reset_index()

        # ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸ ë° 0 ì±„ìš°ê¸°
        for c_code in ['A', 'B', 'C', 'D', 'E', 'F']:
            if c_code not in pdf.columns:
                pdf[c_code] = 0
            else:
                pdf[c_code] = pdf[c_code].fillna(0)

        # 4. ê°œë³„ íšŒì‚¬ Fallback ë¡œì§ ë° ìœ íš¨ ê¸ˆì•¡ ê³„ì‚°
        def process_row(row):
            # A, D ê¸°ë°˜ ìµœì¢… ë¹„ìœ¨ (ë‹¨ìˆœ í‘œì‹œìš©)
            # Dê°€ ìœ íš¨í•˜ê³  Aì™€ ë‹¤ë¥¸ ê²½ìš°ì—ë§Œ 'ê²½ê³¼í›„' ì‚¬ìš©
            if row['D'] > 0 and row['D'] != row['A']:
                final_r = row['D']
                is_fb = False
            else:
                final_r = row['A']
                is_fb = True
            
            # ê°€ì¤‘ í‰ê· ìš© ìœ íš¨ ê¸ˆì•¡ ê³„ì‚°
            # ë¶„ì(ì§€ê¸‰ì—¬ë ¥ê¸ˆì•¡): E > 0 ? E : B
            eff_num = row['E'] if row['E'] > 0 else row['B']
            # ë¶„ëª¨(ê¸°ì¤€ê¸ˆì•¡): F > 0 ? F : C
            eff_den = row['F'] if row['F'] > 0 else row['C']
            
            return pd.Series([final_r, is_fb, eff_num, eff_den])

        pdf[['final_ratio', 'is_fallback', 'eff_num', 'eff_den']] = pdf.apply(process_row, axis=1)

        # 5. í‘œì‹œìš© íšŒì‚¬ëª… ì²˜ë¦¬
        pdf['display_name'] = pdf.apply(
            lambda r: f"{shorten_company_name(r['íšŒì‚¬ëª…'])}*" if r['is_fallback'] else shorten_company_name(r['íšŒì‚¬ëª…']), 
            axis=1
        )

        return pdf, target_month
    except Exception as e:
        st.error(f"íšŒì‚¬ë³„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame(), ""

# ë¶„ì„ìš© ì—…ê¶Œ ë¶„ë¥˜ ì„¤ì • (ì†í•´ ì—…ê¶Œ ì„¸ë¶„í™”ìš©)
EXCLUDE_NON_LIFE = [
    'íŒ©í† ë¦¬ë®¤ì¶”ì–¼ì¸ìŠˆëŸ°ìŠ¤ì»´í¼ë‹ˆ í•œêµ­ì§€ì ',
    'í¼ìŠ¤íŠ¸ì–´ë©”ë¦¬ì¹¸ê¶Œì›ë³´í—˜(ì£¼)í•œêµ­ì§€ì ',
    'ë¯¸ì“°ì´ìŠ¤ë¯¸í† ëª¨í•´ìƒí™”ì¬ë³´í—˜(ì£¼)í•œêµ­ì§€ì ',
    'ìŠ¤íƒ€ì¸í„°ë‚´ì…”ë„ì¸ìŠˆì–´ëŸ°ìŠ¤ì‹±ê°€í¬ë¥´í•œêµ­ì§€ì ',
    'ë™ê²½í•´ìƒì¼ë™í™”ì¬ë³´í—˜(ì£¼)ì„œìš¸ì§€ì [í]',
    'ì„œìš¸ë³´ì¦ë³´í—˜ì£¼ì‹íšŒì‚¬',
    'ë§ˆì´ë¸Œë¼ìš´ë°˜ë ¤ë™ë¬¼ì „ë¬¸ë³´í—˜',
    'ì•Œë¦¬ì•ˆì¸ ê¸€ë¡œë²Œì½”í¼ë ˆì´íŠ¸ì•¤ìŠ¤í˜ì…œí‹°ì—ìŠ¤ì´ í•œêµ­ì§€ì '
]

REINSURANCE_COMPANIES = [
    'ì•Œì§€ì—ì´ ë¦¬ì¸ìŠˆì–´ëŸ°ìŠ¤ ì»´íŒŒë‹ˆ í•œêµ­ì§€ì ',
    'ì½”ë¦¬ì•ˆë¦¬ì¬ë³´í—˜ì£¼ì‹íšŒì‚¬',
    'ìŠ¤ìœ„ìŠ¤ë¦¬ ì•„ì‹œì•„ í”¼í‹°ì´ ì—˜í‹°ë”” í•œêµ­ì§€ì ',
    'ìŠ¤ì½”ë¦¬ì¸ìŠˆì–´ëŸ°ìŠ¤ì•„ì‹œì•„í¼ì‹œí”½í”¼í‹°ì´ì—˜í‹°ë””í•œêµ­ì§€ì ',
    'ë®Œí—¨ì¬ë³´í—˜ì£¼ì‹íšŒì‚¬ í•œêµ­ì§€ì ',
    'ì œë„ˆëŸ´ì¬ë³´í—˜ì£¼ì‹íšŒì‚¬ ì„œìš¸ì§€ì ',
    'í¼ì‹œí”½ë¼ì´í”„ë¦¬ ì¸í„°ë‚´ì…”ë„ í•œêµ­ì§€ì ',
    'í•˜ë…¸ë²„ì¬ë³´í—˜(ì£¼) í•œêµ­ì§€ì '
]

# ==========================================
# 2. ë¹„ë™ê¸° í†µì‹  í•¨ìˆ˜ ì •ì˜
# ==========================================
async def fetch_json(session, url, params):
    try:
        async with session.get(url, params=params, timeout=10) as response:
            if response.status == 200:
                text = await response.text()
                try:
                    return json.loads(text)
                except json.JSONDecodeError:
                    return None
            else:
                return None
    except Exception:
        return None

async def get_companies(session, part_div):
    """ê¸ˆìœµíšŒì‚¬ ì½”ë“œ ì¡°íšŒ"""
    url = f"{BASE_URL}/companySearch.json"
    params = {"lang": "kr", "auth": API_KEY, "partDiv": part_div}
    data = await fetch_json(session, url, params)

    company_list = []
    if data and 'result' in data and 'list' in data['result']:
        for item in data['result']['list']:
            company_list.append({
                'financeCd': item['finance_cd'],
                'financeNm': item['finance_nm'],
                'partDiv': part_div
            })
    return company_list

async def get_accounts(session, list_no):
    """ê³„ì •í•­ëª© ì¡°íšŒ"""
    url = f"{BASE_URL}/accountListSearch.json"
    params = {"lang": "kr", "auth": API_KEY, "listNo": list_no}
    data = await fetch_json(session, url, params)

    account_list = []
    if data and 'result' in data and 'list' in data['result']:
        for item in data['result']['list']:
            account_list.append({
                'accountCd': item['account_cd'],
                'accountNm': item['account_nm'],
                'listNo': list_no
            })
    return account_list

async def fetch_statistics(session, semaphore, company, account, pbar, status_text):
    """í†µê³„ì •ë³´ ìˆ˜ì§‘"""
    url = f"{BASE_URL}/statisticsInfoSearch.json"
    params = {
        "lang": "kr",
        "auth": API_KEY,
        "financeCd": company['financeCd'],
        "listNo": account['listNo'],
        "accountCd": account['accountCd'],
        "term": TERM,
        "startBaseMm": TARGET_MONTH,
        "endBaseMm": TARGET_MONTH
    }

    async with semaphore:
        data = await fetch_json(session, url, params)
    
    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (UI) - ë„ˆë¬´ ì¦ì€ ì—…ë°ì´íŠ¸ëŠ” ì„±ëŠ¥ ì €í•˜ë¥¼ ìœ ë°œí•˜ë¯€ë¡œ ì£¼ì˜
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ë¡œì§ë§Œ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ ë°˜í™˜

    if data and 'result' in data and 'list' in data['result']:
        result_list = data['result']['list']
        if result_list:
            item = result_list[0]
            # ê°’ ìš°ì„ ìˆœìœ„ í™•ì¸
            raw_value = item.get('a') or item.get('won') or item.get('column_value') or 0

            return {
                'êµ¬ë¶„': 'ìƒëª…ë³´í—˜' if company['partDiv'] == 'H' else 'ì†í•´ë³´í—˜',
                'íšŒì‚¬ì½”ë“œ': company['financeCd'],
                'íšŒì‚¬ëª…': company['financeNm'],
                'ê³„ì •ì½”ë“œ': account['accountCd'],
                'ê³„ì •ëª…': account['accountNm'],
                'ê¸°ì¤€ë…„ì›”': TARGET_MONTH, # API ê²°ê³¼ì™€ ìƒê´€ì—†ì´ ìš”ì²­í•œ ê¸°ì¤€ë…„ì›”ë¡œ ì €ì¥ (ì¼ê´€ì„± ìœ ì§€)
                'ë‹¨ìœ„': item.get('unit_name', ''),
                'ê°’': raw_value
            }
    return None

# ==========================================
# 3. ë©”ì¸ ì‹¤í–‰ ë¡œì§ (Async Wrapper)
# ==========================================
async def run_async_collection():
    status_container = st.status("ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ë° ìºì‹œ í™•ì¸ ì¤‘...", expanded=True)
    
    try:
        # 0. MotherDuck ìºì‹œ í™•ì¸
        status_container.write(f"ğŸ” {TARGET_MONTH} ë°ì´í„° ìºì‹œ í™•ì¸ ì¤‘...")
        cached_df = get_cached_data(TARGET_MONTH)
        
        if not cached_df.empty:
            status_container.write(f"âœ… {len(cached_df)}ê±´ì˜ ë°ì´í„°ë¥¼ MotherDuckì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        else:
            status_container.write("â„¹ï¸ í•´ë‹¹ ì›”ì˜ ìºì‹œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        async with aiohttp.ClientSession() as session:
            # 1. ëª©ë¡ ì¡°íšŒ
            status_container.write("ğŸ” 1. ê¸ˆìœµíšŒì‚¬ ë° ê³„ì •í•­ëª© ëª©ë¡ ì¡°íšŒ ì¤‘...")
            
            # ë³‘ë ¬ë¡œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            f1 = get_companies(session, 'H')
            f2 = get_companies(session, 'I')
            f3 = get_accounts(session, 'SH021')
            f4 = get_accounts(session, 'SI021')
            
            life_companies, non_life_companies, life_accounts, non_life_accounts = await asyncio.gather(f1, f2, f3, f4)
            
            total_companies = len(life_companies) + len(non_life_companies)
            status_container.write(f"âœ… íšŒì‚¬ ëª©ë¡ í™•ë³´: ì´ {total_companies}ê°œ")

            # 2. ì‘ì—… ìƒì„± (ìºì‹œì— ì—†ëŠ” ê²ƒë§Œ)
            tasks = []
            semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
            
            status_container.write("ğŸ“¦ 2. ë¯¸ìˆ˜ì§‘ ë°ì´í„° í™•ì¸ ë° ìš”ì²­ ìƒì„± ì¤‘...")
            # ê¸°ì¡´ ë°ì´í„° í‚¤ ìƒì„± (íšŒì‚¬ì½”ë“œ, ê³„ì •ì½”ë“œ)
            existing_keys = set()
            if not cached_df.empty:
                # ë°ì´í„° íƒ€ì…ì„ ë¬¸ìì—´ë¡œ ê°•ì œ ë³€í™˜ ë° ê³µë°± ì œê±° (ìºì‹œ ë¯¸ìŠ¤ ë°©ì§€)
                existing_keys = set(zip(
                    cached_df['íšŒì‚¬ì½”ë“œ'].astype(str).str.strip(), 
                    cached_df['ê³„ì •ì½”ë“œ'].astype(str).str.strip()
                ))

            def build_tasks(companies, accounts):
                for comp in companies:
                    for acc in accounts:
                        # ë¹„êµ ì‹œì—ë„ ë¬¸ìì—´ë¡œ ë³€í™˜ ë° ê³µë°± ì œê±°
                        f_cd = str(comp['financeCd']).strip()
                        a_cd = str(acc['accountCd']).strip()
                        if (f_cd, a_cd) not in existing_keys:
                            tasks.append(fetch_statistics(session, semaphore, comp, acc, None, None))

            build_tasks(life_companies, life_accounts)
            build_tasks(non_life_companies, non_life_accounts)

            total_tasks = len(tasks)
            
            if total_tasks == 0:
                status_container.write("âœ¨ ëª¨ë“  ë°ì´í„°ê°€ ì´ë¯¸ ìºì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                status_container.update(label="âœ… ìºì‹œ ë°ì´í„° ë¦¬ë¡œë“œ ì™„ë£Œ!", state="complete", expanded=False)
                return cached_df.to_dict('records')

            status_container.write(f"ğŸ“¡ {len(existing_keys)}ê±´ì€ ìºì‹œì—ì„œ ë°œê²¬í–ˆê³ , {total_tasks} ê±´ì˜ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ APIë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")

            # 3. ì‹¤í–‰ ë° ì§„í–‰ë¥  í‘œì‹œ
            new_results = []
            progress_bar = status_container.progress(0)
            completed_count = 0
            
            for f in asyncio.as_completed(tasks):
                res = await f
                if res:
                    new_results.append(res)
                
                completed_count += 1
                if total_tasks > 0:
                    progress_bar.progress(completed_count / total_tasks)

            # 4. ìƒˆë¡œìš´ ë°ì´í„° DB ì €ì¥
            if new_results:
                status_container.write(f"ğŸ’¾ {len(new_results)}ê±´ì˜ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ MotherDuckì— ì €ì¥ ì¤‘...")
                new_df = pd.DataFrame(new_results)
                # ê°’ ì „ì²˜ë¦¬ (ì €ì¥ ì „ ìˆ«ìë¡œ ë³€í™˜)
                new_df['ê°’'] = pd.to_numeric(new_df['ê°’'].astype(str).str.replace(',', ''), errors='coerce')
                save_to_md(new_df)
                
                # ê¸°ì¡´ ë°ì´í„°ì™€ í•©ì¹˜ê¸°
                if not cached_df.empty:
                    # ì»¬ëŸ¼ ìˆœì„œ ë° ì´ë¦„ ì¼ê´€ì„± í™•ë³´
                    all_results_df = pd.concat([cached_df[COLUMNS], new_df[COLUMNS]], ignore_index=True)
                    results = all_results_df.to_dict('records')
                else:
                    results = new_results
            else:
                results = cached_df.to_dict('records')

            status_container.update(label="âœ… ë°ì´í„° ìˆ˜ì§‘ ë° ìºì‹± ì™„ë£Œ!", state="complete", expanded=False)
            return results

    except Exception as e:
        status_container.update(label="âš ï¸ ì˜¤ë¥˜ ë°œìƒ", state="error")
        st.error(f"ì˜¤ë¥˜ ìƒì„¸: {e}")
        return []

# ==========================================
# 4. Streamlit UI êµ¬ì„±
# ==========================================
st.title("ğŸ“Š ë³´í—˜ì‚¬ ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# ë©”ì¸ íƒ­ ë¶„ë¦¬: ë¶„ì„ ëŒ€ì‹œë³´ë“œ, íšŒì‚¬ë³„ í˜„í™©, ë°ì´í„° ìˆ˜ì§‘ê¸°
main_tab1, main_tab2, main_tab3 = st.tabs([
    "ğŸ“ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (Dashboard)", 
    "ğŸ“Š íšŒì‚¬ë³„ í˜„í™© (Company Status)", 
    "ğŸ“¡ ë°ì´í„° ìˆ˜ì§‘ê¸° (Collector)"
])

with main_tab1:
    st.subheader("ğŸ“Š K-ICS ë¹„ìœ¨ ì¶”ì´ ë¶„ì„")
    st.info("MotherDuckì— ì €ì¥ëœ ëª¨ë“  ê³¼ê±° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œê³„ì—´ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    
    analysis_df = load_kics_analysis_data()
    
    if not analysis_df.empty:
        # EChartsìš© ë°ì´í„° ì¤€ë¹„
        x_data = sorted(analysis_df['ê¸°ì¤€ë…„ì›”'].unique().tolist())
        
        # ê¸ˆë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        min_month = analysis_df['ê¸°ì¤€ë…„ì›”'].min()
        max_month = analysis_df['ê¸°ì¤€ë…„ì›”'].max()
        bond_df = fetch_ecos_bond_yield(min_month, max_month)
        
        # ê¸ˆë¦¬ ë°ì´í„° ì‹±í¬ ë§ì¶”ê¸°
        if not bond_df.empty:
            kics_months = analysis_df['ê¸°ì¤€ë…„ì›”'].unique()
            bond_df = bond_df[bond_df['ê¸°ì¤€ë…„ì›”'].isin(kics_months)].sort_values('ê¸°ì¤€ë…„ì›”')
        
        # pyecharts Line ê°ì²´ ìƒì„±
        line = Line(init_opts=opts.InitOpts(width="100%", height="600px", theme="white", renderer="svg"))
        line.add_xaxis(xaxis_data=x_data)
        
        # ìƒ‰ìƒ ë§¤í•‘
        colors = {
            'ìƒëª…ë³´í—˜': '#1f77b4',
            'ì†í•´ë³´í—˜': '#ff7f0e',
            'ì „ì²´': '#2ca02c'
        }
        
        for g in ['ìƒëª…ë³´í—˜', 'ì†í•´ë³´í—˜', 'ì „ì²´']:
            # xì¶• ìˆœì„œì— ë§ì¶° ì •ë ¬ ë° ëˆ„ë½ê°’ ì²˜ë¦¬
            g_df = analysis_df[analysis_df['êµ¬ë¶„'] == g].set_index('ê¸°ì¤€ë…„ì›”').reindex(x_data).reset_index()
            
            # ê²½ê³¼ì¡°ì¹˜ í›„ (ì‹¤ì„ )
            line.add_yaxis(
                series_name=f"{g} (ê²½ê³¼ì¡°ì¹˜ í›„)",
                y_axis=[round(float(v), 2) if pd.notnull(v) else None for v in g_df['ratio_after']],
                symbol="circle",
                symbol_size=10,
                linestyle_opts=opts.LineStyleOpts(width=4, color=colors[g]),
                itemstyle_opts=opts.ItemStyleOpts(color=colors[g]),
                label_opts=opts.LabelOpts(is_show=False),
                is_smooth=False,
            )
            
            # ê²½ê³¼ì¡°ì¹˜ ì „ (ì ì„ , ì´ˆê¸° ë¹„í™œì„±í™”)
            line.add_yaxis(
                series_name=f"{g} (ê²½ê³¼ì¡°ì¹˜ ì „)",
                y_axis=[round(float(v), 2) if pd.notnull(v) else None for v in g_df['ratio_before']],
                symbol="circle",
                                symbol_size=8,
                linestyle_opts=opts.LineStyleOpts(width=2, type_="dashed", color=colors[g]),
                itemstyle_opts=opts.ItemStyleOpts(color=colors[g]),
                label_opts=opts.LabelOpts(is_show=False),
                is_smooth=False,
            )
            
        # ë³´ì¡°ì¶• ì¶”ê°€ (ê¸ˆë¦¬ìš©)
        line.extend_axis(
            yaxis=opts.AxisOpts(
                name="ê¸ˆë¦¬ (%)",
                type_="value",
                position="right",
                is_scale=True, # ë°ì´í„° ë²”ìœ„ì— ë§ì¶° ìœ ë™ì  ì¡°ì •
                axislabel_opts=opts.LabelOpts(formatter="{value}%"),
                splitline_opts=opts.SplitLineOpts(is_show=False),
            )
        )
        
        if not bond_df.empty:
            b_df = bond_df.set_index('ê¸°ì¤€ë…„ì›”').reindex(x_data).reset_index()
            line.add_yaxis(
                series_name="êµ­ê³ ì±„ 10ë…„ (ìš°ì¶•)",
                y_axis=[round(float(v), 3) if pd.notnull(v) else None for v in b_df['yield']],
                yaxis_index=1,
                symbol="diamond",
                symbol_size=12,
                linestyle_opts=opts.LineStyleOpts(width=2, type_="dashed", color="#6e7074"),
                itemstyle_opts=opts.ItemStyleOpts(color="#6e7074"),
                label_opts=opts.LabelOpts(is_show=False),
            )
            
        # ì´ˆê¸° ë¹„í™œì„±í™”í•  ì‹œë¦¬ì¦ˆ ë§µ ìƒì„±
        selected_map = {f"{g} (ê²½ê³¼ì¡°ì¹˜ ì „)": False for g in ['ìƒëª…ë³´í—˜', 'ì†í•´ë³´í—˜', 'ì „ì²´']}
        
        line.set_global_opts(
            title_opts=opts.TitleOpts(title="ë³´í—˜ì—…ê¶Œë³„ K-ICS ë¹„ìœ¨ ë° êµ­ê³ ì±„ 10ë…„ ê¸ˆë¦¬ ì¶”ì´", subtitle="ê¸°ì¤€ë…„ì›”ë³„ í˜„í™©"),
            tooltip_opts=opts.TooltipOpts(trigger="axis", axis_pointer_type="cross"),
            xaxis_opts=opts.AxisOpts(name="ê¸°ì¤€ë…„ì›”", type_="category", boundary_gap=True),
            yaxis_opts=opts.AxisOpts(
                name="K-ICS ë¹„ìœ¨ (%)",
                is_scale=True, # ë°ì´í„° ë²”ìœ„ì— ë§ì¶° ìœ ë™ì  ì¡°ì •
                axislabel_opts=opts.LabelOpts(formatter="{value}%"),
                splitline_opts=opts.SplitLineOpts(is_show=True),
            ),
            legend_opts=opts.LegendOpts(
                pos_right="5%", 
                pos_top="5%",
                orient="vertical", # ì°¨íŠ¸ ë‚´ë¶€ ê°€ë…ì„±ì„ ìœ„í•´ ì„¸ë¡œ ë°°ì¹˜
                selected_map=selected_map,
                background_color="rgba(255,255,255,0.7)", # ì•½ê°„ì˜ ë°°ê²½ íˆ¬ëª…ë„
                border_color="#ccc"
            ),
            datazoom_opts=[
                opts.DataZoomOpts(range_start=0, range_end=100), 
                opts.DataZoomOpts(type_="inside", range_start=0, range_end=100)
            ],
            toolbox_opts=opts.ToolboxOpts(is_show=True),
        )
        
        st_pyecharts(line, height="600px", key="dashboard_line_chart")
        
        with st.expander("ğŸ“ ìƒì„¸ ìˆ˜ì¹˜ ë°ì´í„° í™•ì¸"):
            st.dataframe(analysis_df, width="stretch")
    else:
        st.warning("í‘œì‹œí•  ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ë°ì´í„° ìˆ˜ì§‘ê¸°' íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ ì£¼ì„¸ìš”.")
        
        # ë””ë²„ê¹…ì„ ìœ„í•œ ë°ì´í„° í˜„í™© ì„¸ì…˜ (Dashboardì—ì„œë„ ë°ì´í„°ê°€ ì—†ì„ ë•Œ í‘œì‹œ)
        with st.expander("ğŸ› ï¸ ë°ì´í„°ë² ì´ìŠ¤ í˜„í™© í™•ì¸ (ë””ë²„ê¹…)"):
            conn = get_md_connection()
            if conn:
                try:
                    count = conn.execute(f"SELECT COUNT(*) FROM {TABLE_NAME}").fetchone()[0]
                    st.write(f"í˜„ì¬ ì´ ë ˆì½”ë“œ ìˆ˜: {count}ê±´")
                    
                    st.write("ë³´ê´€ ì¤‘ì¸ ê³„ì •ëª… ëª©ë¡:")
                    distinct_accounts = conn.execute(f"SELECT DISTINCT ê³„ì •ëª… FROM {TABLE_NAME}").df()
                    st.dataframe(distinct_accounts, width="stretch")
                    
                    st.write("ë³´ê´€ ì¤‘ì¸ ê¸°ì¤€ë…„ì›” ëª©ë¡:")
                    distinct_months = conn.execute(f"SELECT DISTINCT ê¸°ì¤€ë…„ì›” FROM {TABLE_NAME} ORDER BY ê¸°ì¤€ë…„ì›”").df()
                    st.dataframe(distinct_months, width="stretch")
                    
                    conn.close()
                except Exception as e:
                    st.error(f"í˜„í™© í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            else:
                st.warning("MotherDuck ì—°ê²° ì‹¤íŒ¨ (í† í° í™•ì¸ í•„ìš”)")

with main_tab2:
    st.subheader("ğŸ“Š íšŒì‚¬ë³„ ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨ í˜„í™©")
    
    # ê°€ìš©í•œ ëª¨ë“  ê¸°ì¤€ë…„ì›” ê°€ì ¸ì˜¤ê¸°
    available_months = get_available_months()
    
    if available_months:
        # ê¸°ì¤€ë…„ì›” ì„ íƒ ì˜ì—­
        col_m, col_e = st.columns([1, 2])
        with col_m:
            selected_month = st.selectbox(
                "ğŸ“… ê¸°ì¤€ë…„ì›” ì„ íƒ", 
                options=available_months, 
                index=0,
                help="ì¡°íšŒí•  ê¸°ì¤€ë…„ì›”ì„ ì„ íƒí•˜ì„¸ìš”. ìµœì‹  ë°ì´í„°ê°€ ìƒë‹¨ì— ìœ„ì¹˜í•©ë‹ˆë‹¤."
            )
        
        company_df, latest_m = load_company_solvency_data(selected_month)
    
        if not company_df.empty:
            # ì—…ê¶Œ ì¬ë¶„ë¥˜ ë¡œì§ (ì†í•´ë³´í—˜ ì„¸ë¶„í™”)
            def reclassify_sector(row):
                if row['êµ¬ë¶„'] == 'ìƒëª…ë³´í—˜':
                    return 'ìƒëª…ë³´í—˜'
                elif row['êµ¬ë¶„'] == 'ì†í•´ë³´í—˜':
                    if row['íšŒì‚¬ëª…'] in REINSURANCE_COMPANIES:
                        return 'ì¬ë³´í—˜'
                    elif row['íšŒì‚¬ëª…'] in EXCLUDE_NON_LIFE:
                        return 'ì œì™¸'
                    else:
                        return 'ì†í•´ë³´í—˜'
                return row['êµ¬ë¶„']

            company_df['êµ¬ë¶„'] = company_df.apply(reclassify_sector, axis=1)
            # ì œì™¸ ëŒ€ìƒ ì œê±°
            company_df = company_df[company_df['êµ¬ë¶„'] != 'ì œì™¸'].copy()

            st.markdown(f"**ì¡°íšŒ ì‹œì : {latest_m}** ( * í‘œì‹œ: ê²½ê³¼ì¡°ì¹˜ ì ìš© ì „ ë¹„ìœ¨ ì‚¬ìš© )")
            
            # ì œì™¸í•  íšŒì‚¬ ì„ íƒ UI
            all_companies = sorted(company_df['íšŒì‚¬ëª…'].unique().tolist())
            excluded_companies = st.multiselect(
                "ğŸ“Š ë¹„êµ ë¶„ì„ì—ì„œ ì œì™¸í•  íšŒì‚¬ ì„ íƒ (ì„ íƒ ì‹œ ì°¨íŠ¸ì—ì„œ ì œê±°ë©ë‹ˆë‹¤)",
                options=all_companies,
                default=[],
                help="ë°ì´í„°ê°’ì´ ë¹„ì •ìƒì ìœ¼ë¡œ í¬ê±°ë‚˜ ì‘ì•„ ì°¨íŠ¸ì˜ ì „ì²´ í˜•íƒœë¥¼ ì™œê³¡í•˜ëŠ” íšŒì‚¬ë¥¼ ì œì™¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
            
            # í•„í„°ë§ ì ìš©
            filtered_df = company_df[~company_df['íšŒì‚¬ëª…'].isin(excluded_companies)].copy()
            
            # íšŒì‚¬ëª… ì¶•ì•½ ì ìš© (ì‹œê°í™”ìš©)
            filtered_df['short_display_name'] = filtered_df.apply(
                lambda r: f"{shorten_company_name(r['íšŒì‚¬ëª…'])}*" if r['is_fallback'] else shorten_company_name(r['íšŒì‚¬ëª…']), 
                axis=1
            )
            
            # ìƒ‰ìƒ ì„¤ì • (ì—°í•œ ìƒ‰, ì§„í•œ ìƒ‰)
            color_sets = {
                'ìƒëª…ë³´í—˜': ['#A6CEE3', '#1F78B4'], 
                'ì†í•´ë³´í—˜': ['#FDBF6F', '#FF7F00'],
                'ì¬ë³´í—˜': ['#B2DF8A', '#33A02C']  # ì—°í•œ ì´ˆë¡, ì§„í•œ ì´ˆë¡
            }

            # ì°¨íŠ¸ ë Œë”ë§ ë¡œì§ (ìƒë‹¨ 2ì—´: ìƒëª…/ì†í•´, í•˜ë‹¨ 1ì—´: ì¬ë³´í—˜)
            col_l, col_r = st.columns(2)
            for i, sector in enumerate(['ìƒëª…ë³´í—˜', 'ì†í•´ë³´í—˜']):
                target_col = col_l if i == 0 else col_r
                with target_col:
                    sector_df = company_df[company_df['êµ¬ë¶„'] == sector]
                    sum_num = sector_df['eff_num'].sum()
                    sum_den = sector_df['eff_den'].sum()
                    weighted_avg = (sum_num / sum_den * 100) if sum_den > 0 else 0
                    
                    render_sector_chart(sector, filtered_df, company_df, color_sets, weighted_avg)
            
            st.divider()
            # ì¬ë³´í—˜ ì°¨íŠ¸ (ìƒë‹¨ ì°¨íŠ¸ì™€ widthë¥¼ ë§ì¶”ê¸° ìœ„í•´ 2ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ ì‚¬ìš©)
            col_re, col_empty = st.columns(2)
            with col_re:
                sector = 'ì¬ë³´í—˜'
                sector_df = company_df[company_df['êµ¬ë¶„'] == sector]
                sum_num = sector_df['eff_num'].sum()
                sum_den = sector_df['eff_den'].sum()
                weighted_avg = (sum_num / sum_den * 100) if sum_den > 0 else 0
                render_sector_chart(sector, filtered_df, company_df, color_sets, weighted_avg)
            
            with st.expander("ğŸ“ ìƒì„¸ ë°ì´í„° í™•ì¸"):
                # í‘œì‹œìš© ë°ì´í„°í”„ë ˆì„ êµ¬ì„±
                display_df = filtered_df.copy()
                # A, D ì»¬ëŸ¼ì´ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                for col in ['A', 'D']:
                    if col not in display_df.columns:
                        display_df[col] = 0
                
                st.dataframe(display_df[['êµ¬ë¶„', 'íšŒì‚¬ëª…', 'D', 'A', 'final_ratio', 'is_fallback']].rename(
                    columns={
                        'D': 'ë¹„ìœ¨(ê²½ê³¼í›„)', 
                        'A': 'ë¹„ìœ¨(ê²½ê³¼ì „)',
                        'final_ratio': 'ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨(%)', 
                        'is_fallback': 'ê²½ê³¼ì „ì‚¬ìš©ì—¬ë¶€'
                    }
                ), width="stretch")
        else:
            st.warning(f"{selected_month}ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„° ìˆ˜ì§‘ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”.")
    else:
        st.warning("í‘œì‹œí•  íšŒì‚¬ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ë°ì´í„° ìˆ˜ì§‘ê¸°' íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ ì£¼ì„¸ìš”.")

with main_tab3:
    st.subheader("ğŸ“¡ FSS Open API ë°ì´í„° ìˆ˜ì§‘")
    
    # ì„¤ì • ì„¹ì…˜ (ê¸°ì¡´ ì‚¬ì´ë“œë°”ì—ì„œ ì´ë™)
    with st.expander("âš™ï¸ ìˆ˜ì§‘ ì„¤ì • (Settings)", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            if not st.secrets.get("FSS_API_KEY"):
                API_KEY = st.text_input(
                    "ê¸ˆìœµê°ë…ì› API Key", 
                    value=API_KEY,
                    type="password",
                    help="ì¸ì¦í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
                )
            else:
                st.success("âœ… API Keyê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                API_KEY = st.secrets.get("FSS_API_KEY")
        
        with col2:
            TARGET_MONTH = st.text_input(
                "ìˆ˜ì§‘ ê¸°ì¤€ë…„ì›” (YYYYMM)", 
                value="202509",
                help="ì¡°íšŒí•˜ê³  ì‹¶ì€ ë…„ì›”ì„ ì…ë ¥í•˜ì„¸ìš”."
            )

    st.markdown(f"""
    Open APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë³´í—˜ì‚¬ì˜ ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨ ê´€ë ¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  MotherDuckì— ì €ì¥í•©ë‹ˆë‹¤.
    - **ëŒ€ìƒ**: ìƒëª…ë³´í—˜(H), ì†í•´ë³´í—˜(I)
    """)
    
    # ì‹¤í–‰ ë²„íŠ¼
    if st.button("ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (Start Collection)", type="primary"):
        if not API_KEY:
            st.error("API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥ ê°€ëŠ¥)")
        else:
            # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
            raw_data = asyncio.run(run_async_collection())

            if raw_data:
                df = pd.DataFrame(raw_data)
                
                # ì „ì²˜ë¦¬
                df['ê°’'] = pd.to_numeric(df['ê°’'].astype(str).str.replace(',', ''), errors='coerce')

                # í”¼ë²— í…Œì´ë¸”
                df_pivot = df.pivot_table(
                    index=['êµ¬ë¶„', 'íšŒì‚¬ëª…', 'ê¸°ì¤€ë…„ì›”'],
                    columns='ê³„ì •ëª…',
                    values='ê°’',
                    aggfunc='first'
                ).reset_index()

                # ê²°ê³¼ ì„¹ì…˜
                st.divider()
                st.success(f"âœ… {TARGET_MONTH} ë°ì´í„° ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                tab_res1, tab_res2 = st.tabs(["ğŸ“‹ ìš”ì•½ í…Œì´ë¸” (Pivot)", "ğŸ“„ RAW ë°ì´í„°"])
                
                with tab_res1:
                    st.subheader(f"{TARGET_MONTH} ìˆ˜ì§‘ ê²°ê³¼ (ìš”ì•½)")
                    st.dataframe(df_pivot, width="stretch")
                    
                    # CSV ë‹¤ìš´ë¡œë“œ
                    csv = df_pivot.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ğŸ’¾ ìˆ˜ì§‘ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                        data=csv,
                        file_name=f"insurance_solvency_{TARGET_MONTH}_result.csv",
                        mime="text/csv"
                    )

                with tab_res2:
                    st.subheader(f"{TARGET_MONTH} RAW ë°ì´í„°")
                    st.dataframe(df, width="stretch")
                
                # ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìœ¼ë‹ˆ í™”ë©´ ê°±ì‹ ì„ ìœ ë„í•˜ê±°ë‚˜ ì •ë³´ë¥¼ ì œê³µ
                st.info("ğŸ’¡ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. 'ë¶„ì„ ëŒ€ì‹œë³´ë“œ' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì—¬ ì°¨íŠ¸ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.")
            else:
                st.warning("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. API Keyë‚˜ ê¸°ì¤€ë…„ì›”ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")