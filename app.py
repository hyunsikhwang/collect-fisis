import streamlit as st
import aiohttp
import asyncio
import pandas as pd
import nest_asyncio
import json
import time
import duckdb
import os

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë³´í—˜ì‚¬ ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨ ìˆ˜ì§‘ê¸°",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ë¹„ë™ê¸° ë£¨í”„ ì¶©ëŒ ë°©ì§€
nest_asyncio.apply()

# ==========================================
# 1. ìƒìˆ˜ ë° ì„¤ì • (ì‚¬ì´ë“œë°” ì…ë ¥)
# ==========================================
st.sidebar.header("âš™ï¸ ì„¤ì • (Settings)")

# API í‚¤ (st.secrets ì²˜ë¦¬)
API_KEY = st.secrets.get("FSS_API_KEY", "")

if not API_KEY:
    API_KEY = st.sidebar.text_input(
        "ê¸ˆìœµê°ë…ì› API Key", 
        type="password",
        help="ê¸ˆìœµê°ë…ì› Open API ì¸ì¦í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”. (ê³„ì† ì‚¬ìš©í•˜ì‹œë ¤ë©´ .streamlit/secrets.tomlì— FSS_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.)"
    )
else:
    st.sidebar.success("âœ… API Keyê°€ secretsì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")


TARGET_MONTH = st.sidebar.text_input(
    "ê¸°ì¤€ë…„ì›” (YYYYMM)", 
    value="202506",
    help="ì¡°íšŒí•˜ê³  ì‹¶ì€ ë…„ì›”ì„ ì…ë ¥í•˜ì„¸ìš”."
)

TERM = "Q" # ë¶„ê¸°
BASE_URL = "http://fisis.fss.or.kr/openapi"
MAX_CONCURRENT_REQUESTS = 20

# ==========================================
# 1.5. MotherDuck DB ì„¤ì •
# ==========================================
MD_TOKEN = st.secrets.get("MOTHERDUCK_TOKEN", "")
DB_NAME = "fisis_cache"
TABLE_NAME = "insurance_stats"

def get_md_connection():
    """MotherDuck ì—°ê²° ì„¤ì •"""
    if not MD_TOKEN:
        return None
    try:
        # MotherDuck ì—°ê²° (md: ë’¤ì— í† í°ì´ ì—†ìœ¼ë©´ st.secretsì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ í™•ì¸)
        conn = duckdb.connect(f"md:{DB_NAME}?motherduck_token={MD_TOKEN}")
        # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±
        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {TABLE_NAME} (
                êµ¬ë¶„ VARCHAR,
                íšŒì‚¬ì½”ë“œ VARCHAR,
                íšŒì‚¬ëª… VARCHAR,
                ê³„ì •ì½”ë“œ VARCHAR,
                ê³„ì •ëª… VARCHAR,
                ê¸°ì¤€ë…„ì›” VARCHAR,
                ë‹¨ìœ„ VARCHAR,
                ê°’ DOUBLE,
                ìˆ˜ì§‘ì¼ì‹œ TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        return conn
    except Exception as e:
        st.error(f"MotherDuck ì—°ê²° ì˜¤ë¥˜: {e}")
        return None

def get_cached_data(target_month):
    """MotherDuckì—ì„œ ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ"""
    conn = get_md_connection()
    if conn:
        try:
            df = conn.execute(f"SELECT * FROM {TABLE_NAME} WHERE ê¸°ì¤€ë…„ì›” = ?", [target_month]).df()
            conn.close()
            return df
        except Exception as e:
            st.warning(f"ë°ì´í„° ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

def save_to_md(df):
    """ë°ì´í„°ë¥¼ MotherDuckì— ì €ì¥"""
    if df.empty:
        return
    conn = get_md_connection()
    if conn:
        try:
            # ì„ì‹œ ë·°ë¥¼ ìƒì„±í•˜ì—¬ ë°ì´í„°ë¥¼ ì ì¬
            conn.register("df_to_save", df)
            conn.execute(f"INSERT INTO {TABLE_NAME} SELECT * EXCLUDE(ìˆ˜ì§‘ì¼ì‹œ), CURRENT_TIMESTAMP FROM df_to_save")
            conn.close()
        except Exception as e:
            st.error(f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

# ==========================================
# 2. ë¹„ë™ê¸° í†µì‹  í•¨ìˆ˜ ì •ì˜
# ==========================================
async def fetch_json(session, url, params):
    try:
        async with session.get(url, params=params, timeout=10) as response:
            if response.status == 200:
                text = await response.text()
                try:
                    return json.loads(text)
                except json.JSONDecodeError:
                    return None
            else:
                return None
    except Exception:
        return None

async def get_companies(session, part_div):
    """ê¸ˆìœµíšŒì‚¬ ì½”ë“œ ì¡°íšŒ"""
    url = f"{BASE_URL}/companySearch.json"
    params = {"lang": "kr", "auth": API_KEY, "partDiv": part_div}
    data = await fetch_json(session, url, params)

    company_list = []
    if data and 'result' in data and 'list' in data['result']:
        for item in data['result']['list']:
            company_list.append({
                'financeCd': item['finance_cd'],
                'financeNm': item['finance_nm'],
                'partDiv': part_div
            })
    return company_list

async def get_accounts(session, list_no):
    """ê³„ì •í•­ëª© ì¡°íšŒ"""
    url = f"{BASE_URL}/accountListSearch.json"
    params = {"lang": "kr", "auth": API_KEY, "listNo": list_no}
    data = await fetch_json(session, url, params)

    account_list = []
    if data and 'result' in data and 'list' in data['result']:
        for item in data['result']['list']:
            account_list.append({
                'accountCd': item['account_cd'],
                'accountNm': item['account_nm'],
                'listNo': list_no
            })
    return account_list

async def fetch_statistics(session, semaphore, company, account, pbar, status_text):
    """í†µê³„ì •ë³´ ìˆ˜ì§‘"""
    url = f"{BASE_URL}/statisticsInfoSearch.json"
    params = {
        "lang": "kr",
        "auth": API_KEY,
        "financeCd": company['financeCd'],
        "listNo": account['listNo'],
        "accountCd": account['accountCd'],
        "term": TERM,
        "startBaseMm": TARGET_MONTH,
        "endBaseMm": TARGET_MONTH
    }

    async with semaphore:
        data = await fetch_json(session, url, params)
    
    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (UI) - ë„ˆë¬´ ì¦ì€ ì—…ë°ì´íŠ¸ëŠ” ì„±ëŠ¥ ì €í•˜ë¥¼ ìœ ë°œí•˜ë¯€ë¡œ ì£¼ì˜
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ë¡œì§ë§Œ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ ë°˜í™˜

    if data and 'result' in data and 'list' in data['result']:
        result_list = data['result']['list']
        if result_list:
            item = result_list[0]
            # ê°’ ìš°ì„ ìˆœìœ„ í™•ì¸
            raw_value = item.get('a') or item.get('won') or item.get('column_value') or 0

            return {
                'êµ¬ë¶„': 'ìƒëª…ë³´í—˜' if company['partDiv'] == 'H' else 'ì†í•´ë³´í—˜',
                'íšŒì‚¬ì½”ë“œ': company['financeCd'],
                'íšŒì‚¬ëª…': company['financeNm'],
                'ê³„ì •ì½”ë“œ': account['accountCd'],
                'ê³„ì •ëª…': account['accountNm'],
                'ê¸°ì¤€ë…„ì›”': item.get('base_month', TARGET_MONTH),
                'ë‹¨ìœ„': item.get('unit_name', ''),
                'ê°’': raw_value
            }
    return None

# ==========================================
# 3. ë©”ì¸ ì‹¤í–‰ ë¡œì§ (Async Wrapper)
# ==========================================
async def run_async_collection():
    status_container = st.status("ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ë° ìºì‹œ í™•ì¸ ì¤‘...", expanded=True)
    
    try:
        # 0. MotherDuck ìºì‹œ í™•ì¸
        status_container.write(f"ğŸ” {TARGET_MONTH} ë°ì´í„° ìºì‹œ í™•ì¸ ì¤‘...")
        cached_df = get_cached_data(TARGET_MONTH)
        
        if not cached_df.empty:
            status_container.write(f"âœ… {len(cached_df)}ê±´ì˜ ë°ì´í„°ë¥¼ MotherDuckì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        
        async with aiohttp.ClientSession() as session:
            # 1. ëª©ë¡ ì¡°íšŒ
            status_container.write("ğŸ” 1. ê¸ˆìœµíšŒì‚¬ ë° ê³„ì •í•­ëª© ëª©ë¡ ì¡°íšŒ ì¤‘...")
            
            # ë³‘ë ¬ë¡œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            f1 = get_companies(session, 'H')
            f2 = get_companies(session, 'I')
            f3 = get_accounts(session, 'SH021')
            f4 = get_accounts(session, 'SI021')
            
            life_companies, non_life_companies, life_accounts, non_life_accounts = await asyncio.gather(f1, f2, f3, f4)
            
            total_companies = len(life_companies) + len(non_life_companies)
            status_container.write(f"âœ… íšŒì‚¬ ëª©ë¡ í™•ë³´: ì´ {total_companies}ê°œ")

            # 2. ì‘ì—… ìƒì„± (ìºì‹œì— ì—†ëŠ” ê²ƒë§Œ)
            tasks = []
            semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
            
            status_container.write("ğŸ“¦ 2. ë¯¸ìˆ˜ì§‘ ë°ì´í„° í™•ì¸ ë° ìš”ì²­ ìƒì„± ì¤‘...")
            
            # ê¸°ì¡´ ë°ì´í„° í‚¤ ìƒì„± (íšŒì‚¬ì½”ë“œ, ê³„ì •ì½”ë“œ)
            existing_keys = set()
            if not cached_df.empty:
                existing_keys = set(zip(cached_df['íšŒì‚¬ì½”ë“œ'], cached_df['ê³„ì •ì½”ë“œ']))

            def build_tasks(companies, accounts):
                for comp in companies:
                    for acc in accounts:
                        if (comp['financeCd'], acc['accountCd']) not in existing_keys:
                            tasks.append(fetch_statistics(session, semaphore, comp, acc, None, None))

            build_tasks(life_companies, life_accounts)
            build_tasks(non_life_companies, non_life_accounts)

            total_tasks = len(tasks)
            
            if total_tasks == 0:
                status_container.write("âœ¨ ëª¨ë“  ë°ì´í„°ê°€ ì´ë¯¸ ìºì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                status_container.update(label="âœ… ìºì‹œ ë°ì´í„° ë¦¬ë¡œë“œ ì™„ë£Œ!", state="complete", expanded=False)
                return cached_df.to_dict('records')

            status_container.write(f"ğŸ“¡ ì´ {total_tasks} ê±´ì˜ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ APIë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")

            # 3. ì‹¤í–‰ ë° ì§„í–‰ë¥  í‘œì‹œ
            new_results = []
            progress_bar = status_container.progress(0)
            completed_count = 0
            
            for f in asyncio.as_completed(tasks):
                res = await f
                if res:
                    new_results.append(res)
                
                completed_count += 1
                if total_tasks > 0:
                    progress_bar.progress(completed_count / total_tasks)

            # 4. ìƒˆë¡œìš´ ë°ì´í„° DB ì €ì¥
            if new_results:
                status_container.write(f"ğŸ’¾ {len(new_results)}ê±´ì˜ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ MotherDuckì— ì €ì¥ ì¤‘...")
                new_df = pd.DataFrame(new_results)
                # ê°’ ì „ì²˜ë¦¬ (ì €ì¥ ì „ ìˆ«ìë¡œ ë³€í™˜)
                new_df['ê°’'] = pd.to_numeric(new_df['ê°’'].astype(str).str.replace(',', ''), errors='coerce')
                save_to_md(new_df)
                
                # ê¸°ì¡´ ë°ì´í„°ì™€ í•©ì¹˜ê¸°
                if not cached_df.empty:
                    # ìˆ˜ì§‘ì¼ì‹œ ì»¬ëŸ¼ ì œì™¸í•˜ê³  í•©ì¹˜ê¸° (cached_dfì—ëŠ” ìˆ˜ì§‘ì¼ì‹œê°€ ìˆì„ ìˆ˜ ìˆìŒ)
                    cols = ['êµ¬ë¶„', 'íšŒì‚¬ì½”ë“œ', 'íšŒì‚¬ëª…', 'ê³„ì •ì½”ë“œ', 'ê³„ì •ëª…', 'ê¸°ì¤€ë…„ì›”', 'ë‹¨ìœ„', 'ê°’']
                    all_results_df = pd.concat([cached_df[cols], new_df[cols]], ignore_index=True)
                    results = all_results_df.to_dict('records')
                else:
                    results = new_results
            else:
                results = cached_df.to_dict('records')

            status_container.update(label="âœ… ë°ì´í„° ìˆ˜ì§‘ ë° ìºì‹± ì™„ë£Œ!", state="complete", expanded=False)
            return results

    except Exception as e:
        status_container.update(label="âš ï¸ ì˜¤ë¥˜ ë°œìƒ", state="error")
        st.error(f"ì˜¤ë¥˜ ìƒì„¸: {e}")
        return []

# ==========================================
# 4. Streamlit UI êµ¬ì„±
# ==========================================
st.title("ğŸ“Š ë³´í—˜ì‚¬ ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨ ì¡°íšŒê¸°")
st.markdown(f"""
ê¸ˆìœµê°ë…ì› Open APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë³´í—˜ì‚¬ì˜ ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨ ê´€ë ¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
- **ê¸°ì¤€ë…„ì›”**: {TARGET_MONTH}
- **ëŒ€ìƒ**: ìƒëª…ë³´í—˜(H), ì†í•´ë³´í—˜(I)
""")

# ì‹¤í–‰ ë²„íŠ¼
if st.button("ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (Start)", type="primary"):
    if not API_KEY:
        st.error("API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
        raw_data = asyncio.run(run_async_collection())

        if raw_data:
            df = pd.DataFrame(raw_data)
            
            # ì „ì²˜ë¦¬
            df['ê°’'] = pd.to_numeric(df['ê°’'].astype(str).str.replace(',', ''), errors='coerce')

            # í”¼ë²— í…Œì´ë¸”
            df_pivot = df.pivot_table(
                index=['êµ¬ë¶„', 'íšŒì‚¬ëª…', 'ê¸°ì¤€ë…„ì›”'],
                columns='ê³„ì •ëª…',
                values='ê°’',
                aggfunc='first'
            ).reset_index()

            # ê²°ê³¼ íƒ­ êµ¬ì„±
            tab1, tab2 = st.tabs(["ğŸ“‹ ìš”ì•½ í…Œì´ë¸” (Pivot)", "raw ì›ë³¸ ë°ì´í„°"])

            with tab1:
                st.subheader("ê²°ê³¼ ë°ì´í„°")
                st.dataframe(df_pivot, use_container_width=True)
                
                # CSV ë‹¤ìš´ë¡œë“œ
                csv = df_pivot.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                    data=csv,
                    file_name=f"insurance_solvency_{TARGET_MONTH}_pivot.csv",
                    mime="text/csv"
                )

            with tab2:
                st.dataframe(df, use_container_width=True)
        else:
            st.warning("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. API Keyë‚˜ ê¸°ì¤€ë…„ì›”ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")