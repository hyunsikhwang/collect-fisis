import streamlit as st
import aiohttp
import asyncio
import pandas as pd
import nest_asyncio
import json
import time
import duckdb
import os
import requests
from datetime import datetime
from pytz import timezone
from streamlit_echarts import st_pyecharts
from pyecharts import options as opts
from pyecharts.charts import Line, Bar
from pyecharts.commons.utils import JsCode

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë³´í—˜ì‚¬ ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨ ìˆ˜ì§‘ê¸°",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ë¹„ë™ê¸° ë£¨í”„ ì¶©ëŒ ë°©ì§€
nest_asyncio.apply()

# ==========================================
# 1. ìƒìˆ˜ ë° ê¸°ë³¸ ì„¤ì •
# ==========================================
# API í‚¤ (st.secrets ì²˜ë¦¬ í›„ í•„ìš”ì‹œ UIì—ì„œ ì…ë ¥)
API_KEY = st.secrets.get("FSS_API_KEY", "")
TARGET_MONTH = "202509" # ê¸°ë³¸ê°’ ì„¤ì •

TERM = "Q" # ë¶„ê¸°
BASE_URL = "http://fisis.fss.or.kr/openapi"
MAX_CONCURRENT_REQUESTS = 20

# ==========================================
# 1.5. MotherDuck DB ì„¤ì •
# ==========================================
MD_TOKEN = st.secrets.get("MOTHERDUCK_TOKEN", "")
DB_NAME = "fisis_cache"
TABLE_NAME = "insurance_stats"
COLUMNS = ['êµ¬ë¶„', 'íšŒì‚¬ì½”ë“œ', 'íšŒì‚¬ëª…', 'ê³„ì •ì½”ë“œ', 'ê³„ì •ëª…', 'ê¸°ì¤€ë…„ì›”', 'ë‹¨ìœ„', 'ê°’']

# íšŒì‚¬ëª… í•œ/ì˜ ë§¤í•‘ (í‘œì‹œìš©)
CompKoEn = {
    'DBìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'DB Life',
    'DGBìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'iM(DGB) Life',
    'ì•„ì´ì— ë¼ì´í”„ìƒëª…ë³´í—˜ ì£¼ì‹íšŒì‚¬': 'iM(DGB) Life',
    'KBë¼ì´í”„ìƒëª…ë³´í—˜': 'KB Life',
    'êµë³´ë¼ì´í”„í”Œë˜ë‹›ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'KyoboLP Life',
    'êµë³´ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Kyobo Life',
    'ë†í˜‘ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'NH Life',
    'ë¯¸ë˜ì—ì…‹ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'MiraeAsset Life',
    'ì‚¼ì„±ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Samsung Life',
    'ì‹ í•œë¼ì´í”„ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Shinhan Life',
    'ì•„ì´ë¹„ì¼€ì´ì—°ê¸ˆë³´í—˜ ì£¼ì‹íšŒì‚¬': 'IBK Life',
    'ì¼€ì´ë””ë¹„ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'KDB Life',
    'í•˜ë‚˜ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Hana Life',
    'í•œí™”ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Hanwha Life',
    'í¥êµ­ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'HeungKuk Life',
    'ë™ì–‘ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Tongyang Life',
    'ë¼ì´ë‚˜ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Lina Life',
    'ë©”íŠ¸ë¼ì´í”„ìƒëª…ë³´í—˜(ì£¼)': 'Met Life',
    'ë¹„ì—”í”¼íŒŒë¦¬ë°”ì¹´ë””í”„ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Cardif Life',
    'ì—ì´ë¹„ì—˜ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'ABL Life',
    'ì—ì´ì•„ì´ì—ì´ìƒëª…ë³´í—˜ ì£¼ì‹íšŒì‚¬': 'AIA Life',
    'ì²˜ë¸Œë¼ì´í”„ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Chubb Life',
    'í‘¸ë³¸í˜„ëŒ€ìƒëª…ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Fubon Life',
    'DBì†í•´ë³´í—˜ì£¼ì‹íšŒì‚¬': 'DB FM',
    'ë†í˜‘ì†í•´ë³´í—˜ì£¼ì‹íšŒì‚¬': 'NH FM',
    'ë¡¯ë°ì†í•´ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Lotte FM',
    'ë©”ë¦¬ì¸ í™”ì¬í•´ìƒë³´í—˜ì£¼ì‹íšŒì‚¬': 'Meritz FM',
    'ì‚¼ì„±í™”ì¬í•´ìƒë³´í—˜ì£¼ì‹íšŒì‚¬': 'Samsung FM',
    'ì— ì§€ì†í•´ë³´í—˜ì£¼ì‹íšŒì‚¬': 'MG FM',
    'ì£¼ì‹íšŒì‚¬KBì†í•´ë³´í—˜': 'KB FM',
    'í•˜ë‚˜ì†í•´ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Hana FM',
    'í•œí™”ì†í•´ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Hanwha FM',
    'í˜„ëŒ€í•´ìƒí™”ì¬ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Hyundai FM',
    'í¥êµ­í™”ì¬í•´ìƒë³´í—˜ì£¼ì‹íšŒì‚¬': 'Heungkuk FM',
    'ì‹ í•œEZì†í•´ë³´í—˜ì£¼ì‹íšŒì‚¬': 'ShinhanEZ FM',
    'ì£¼ì‹íšŒì‚¬ ì¹´ì¹´ì˜¤í˜ì´ì†í•´ë³´í—˜': 'Kakao FM',
    'ìºë¡¯ì†í•´ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Carrot FM',
    'ì•…ì‚¬ì†í•´ë³´í—˜ì£¼ì‹íšŒì‚¬': 'AXA FM',
    'ì—ì´ìŠ¤ì•„ë©”ë¦¬ì¹¸í™”ì¬í•´ìƒë³´í—˜ì£¼ì‹íšŒì‚¬': 'Ace FM',
    'ì—ì´ì•„ì´ì§€ì†í•´ë³´í—˜ì£¼ì‹íšŒì‚¬': 'AIG FM',
    'ë®Œí—¨ì¬ë³´í—˜ì£¼ì‹íšŒì‚¬ í•œêµ­ì§€ì ': 'Munich Re',
    'ìŠ¤ìœ„ìŠ¤ë¦¬ ì•„ì‹œì•„ í”¼í‹°ì´ ì—˜í‹°ë”” í•œêµ­ì§€ì ': 'Swiss Re',
    'ìŠ¤ì½”ë¦¬ì¸ìŠˆì–´ëŸ°ìŠ¤ì•„ì‹œì•„í¼ì‹œí”½í”¼í‹°ì´ì—˜í‹°ë””í•œêµ­ì§€ì ': 'Scor Re',
    'ì•Œì§€ì—ì´ ë¦¬ì¸ìŠˆì–´ëŸ°ìŠ¤ ì»´íŒŒë‹ˆ í•œêµ­ì§€ì ': 'RGA',
    'ì œë„ˆëŸ´ì¬ë³´í—˜ì£¼ì‹íšŒì‚¬ ì„œìš¸ì§€ì ': 'Gen Re',
    'ì½”ë¦¬ì•ˆë¦¬ì¬ë³´í—˜ì£¼ì‹íšŒì‚¬': 'Korean Re',
    'í¼ì‹œí”½ë¼ì´í”„ë¦¬ ì¸í„°ë‚´ì…”ë„ í•œêµ­ì§€ì ': 'Pacific Re',
    'í•˜ë…¸ë²„ì¬ë³´í—˜(ì£¼) í•œêµ­ì§€ì ': 'Hanover Re'
}

def get_md_connection():
    """MotherDuck ì—°ê²° ì„¤ì •"""
    if not MD_TOKEN:
        return None
    try:
        # MotherDuck ì—°ê²° (md: ë’¤ì— í† í°ì´ ì—†ìœ¼ë©´ st.secretsì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ í™˜ê²½ë³€ìˆ˜ í™•ì¸)
        conn = duckdb.connect(f"md:?motherduck_token={MD_TOKEN}")
        # ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ë° ì‚¬ìš©
        conn.execute(f"CREATE DATABASE IF NOT EXISTS {DB_NAME}")
        conn.execute(f"USE {DB_NAME}")
        # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±
        conn.execute(f"""
            CREATE TABLE IF NOT EXISTS {TABLE_NAME} (
                êµ¬ë¶„ VARCHAR,
                íšŒì‚¬ì½”ë“œ VARCHAR,
                íšŒì‚¬ëª… VARCHAR,
                ê³„ì •ì½”ë“œ VARCHAR,
                ê³„ì •ëª… VARCHAR,
                ê¸°ì¤€ë…„ì›” VARCHAR,
                ë‹¨ìœ„ VARCHAR,
                ê°’ DOUBLE,
                ìˆ˜ì§‘ì¼ì‹œ TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        return conn
    except Exception as e:
        st.error(f"MotherDuck ì—°ê²° ì˜¤ë¥˜: {e}")
        return None

def get_cached_data(target_month):
    """MotherDuckì—ì„œ ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ"""
    conn = get_md_connection()
    if conn:
        try:
            df = conn.execute(f"SELECT * FROM {TABLE_NAME} WHERE ê¸°ì¤€ë…„ì›” = ?", [target_month]).df()
            conn.close()
            return df
        except Exception as e:
            st.warning(f"ë°ì´í„° ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    return pd.DataFrame()

def save_to_md(df):
    """ë°ì´í„°ë¥¼ MotherDuckì— ì €ì¥"""
    if df.empty:
        return
    conn = get_md_connection()
    if conn:
        try:
            # ì»¬ëŸ¼ ìˆœì„œ ê³ ì • ë° ë°ì´í„° í´ë¦¬ë‹
            df_to_save = df[COLUMNS].copy()
            for col in ['íšŒì‚¬ì½”ë“œ', 'ê³„ì •ì½”ë“œ', 'ê¸°ì¤€ë…„ì›”']:
                df_to_save[col] = df_to_save[col].astype(str).str.strip()

            # ì„ì‹œ ë·°ë¥¼ ìƒì„±í•˜ì—¬ ë°ì´í„°ë¥¼ ì ì¬
            conn.register("df_to_save", df_to_save)
            # ëª…ì‹œì ìœ¼ë¡œ ì»¬ëŸ¼ì„ ì§€ì •í•˜ì—¬ INSERT (ìˆœì„œ ì¼ê´€ì„± ë³´ì¥)
            col_names = ", ".join(COLUMNS) + ", ìˆ˜ì§‘ì¼ì‹œ"
            conn.execute(f"INSERT INTO {TABLE_NAME} ({col_names}) SELECT *, CURRENT_TIMESTAMP FROM df_to_save")
            conn.close()
        except Exception as e:
            st.error(f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

def load_kics_analysis_data():
    """K-ICS ë¶„ì„ì„ ìœ„í•œ ì „ì²´ ë°ì´í„° ë¡œë“œ ë° ê³„ì‚°"""
    conn = get_md_connection()
    if not conn:
        return pd.DataFrame()
    
    try:
        # ê´€ì‹¬ ìˆëŠ” ê³„ì •ë“¤ë§Œ í•„í„°ë§í•´ì„œ ê°€ì ¸ì˜¤ê¸°
        target_accounts = [
            'ì§€ê¸‰ì—¬ë ¥ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© ì „)', 
            'ì§€ê¸‰ì—¬ë ¥ê¸°ì¤€ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© ì „)',
            'ì§€ê¸‰ì—¬ë ¥ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© í›„)', 
            'ì§€ê¸‰ì—¬ë ¥ê¸°ì¤€ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© í›„)'
        ]
        
        # [DEBUG] ë””ë²„ê¹… ì˜µì…˜ (Dashboard ìƒë‹¨ì— í‘œì‹œë¨)
        show_debug = st.checkbox("ğŸ” ìƒì„¸ ë°ì´í„° ì¶”ì¶œ ê³¼ì • í™•ì¸ (ë””ë²„ê±°)", value=False)
        
        # 1. DBì— ìˆëŠ” ëª¨ë“  ë…íŠ¹í•œ ê³„ì •ëª… í™•ì¸
        all_accounts = conn.execute(f"SELECT DISTINCT ê³„ì •ëª… FROM {TABLE_NAME}").df()['ê³„ì •ëª…'].tolist()
        if show_debug:
            st.write(f"DEBUG: DB ë‚´ ì´ ê³„ì • ìˆ˜: {len(all_accounts)}")
            st.write(f"DEBUG: DB ë‚´ ê³„ì • ìƒ˜í”Œ: {all_accounts[:5]}")
        
        # 2. ìœ ì‚¬í•œ ê³„ì •ëª… ë§¤í•‘ (ê³µë°± ì œê±° ë° ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰ìœ¼ë¡œ ê°•í™”)
        def find_best_match(target, candidates):
            target_clean = target.replace(" ", "")
            # ì™„ì „ ì¼ì¹˜(ê³µë°± ì œê±°)
            for c in candidates:
                if c.replace(" ", "") == target_clean:
                    return c
            # ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰
            for c in candidates:
                if target_clean in c.replace(" ", "") or c.replace(" ", "") in target_clean:
                    return c
            return target

        actual_targets = [find_best_match(t, all_accounts) for t in target_accounts]
        if show_debug:
            st.write(f"DEBUG: ë§¤í•‘ëœ íƒ€ê²Ÿ ê³„ì •: {actual_targets}")
        
        # IN ì ˆ íŒŒë¼ë¯¸í„° ìƒì„±
        placeholders = ', '.join(['?' for _ in actual_targets])
        query = f"SELECT * FROM {TABLE_NAME} WHERE ê³„ì •ëª… IN ({placeholders})"
        df = conn.execute(query, actual_targets).df()
        conn.close()
        
        if show_debug:
            st.write(f"DEBUG: ì¡°íšŒëœ ë¡œìš° ìˆ˜: {len(df)}")

        if df.empty:
            return pd.DataFrame()

        # ë°ì´í„° í´ë¦¬ë‹
        df['ê¸°ì¤€ë…„ì›”'] = df['ê¸°ì¤€ë…„ì›”'].astype(str).str.strip()
        
        # ë§¤í•‘ìš© ì‚¬ì „ ìƒì„± (ì›ë˜ ì´ë¦„ìœ¼ë¡œ í†µì¼)
        name_map = dict(zip(actual_targets, target_accounts))
        df['ê³„ì •ëª…'] = df['ê³„ì •ëª…'].map(name_map)
        
        if show_debug:
            st.write("DEBUG: ê³„ì •ëª… ë§¤í•‘ í›„ ë°ì´í„° ìƒ˜í”Œ:", df.head())

        # í”¼ë²—í•˜ì—¬ ê³„ì‚°í•˜ê¸° ì‰½ê²Œ ë³€í™˜
        # ê³„ì •ëª…ì´ ì¤‘ë³µë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ (ë™ì¼ íšŒì‚¬ê°€ ê°™ì€ ë‹¬ì— ì—¬ëŸ¬ë²ˆ ìˆ˜ì§‘ëœ ê²½ìš° ë“±) sumìœ¼ë¡œ ì§‘ê³„
        pdf = df.pivot_table(
            index=['êµ¬ë¶„', 'ê¸°ì¤€ë…„ì›”', 'íšŒì‚¬ëª…'],
            columns='ê³„ì •ëª…',
            values='ê°’',
            aggfunc='sum'
        ).reset_index()
        
        if show_debug:
            st.write("DEBUG: í”¼ë²— í›„ ë°ì´í„° ì»¬ëŸ¼:", pdf.columns.tolist())
            st.write("DEBUG: í”¼ë²— í›„ ë°ì´í„° ìˆ˜:", len(pdf))
        # í•„ìš”í•œ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸ (ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì±„ì›€)
        for col in target_accounts:
            if col not in pdf.columns:
                pdf[col] = 0

        # ê·¸ë£¹ë³„ í•©ê³„ ê³„ì‚° (ìƒëª…ë³´í—˜, ì†í•´ë³´í—˜, ì „ì²´)
        # 1. ìƒëª…/ì†í•´ë³„ í•©ê³„
        grouped = pdf.groupby(['êµ¬ë¶„', 'ê¸°ì¤€ë…„ì›”'])[target_accounts].sum().reset_index()
        
        # 2. ì „ì²´(Total) í•©ê³„ ìƒì„±
        total = pdf.groupby(['ê¸°ì¤€ë…„ì›”'])[target_accounts].sum().reset_index()
        total['êµ¬ë¶„'] = 'ì „ì²´'
        
        # ê²°í•©
        final_df = pd.concat([grouped, total], ignore_index=True)
        
        # K-ICS ë¹„ìœ¨ ê³„ì‚° (%)
        # ê²½ê³¼ì¡°ì¹˜ ì „
        final_df['ratio_before'] = (final_df['ì§€ê¸‰ì—¬ë ¥ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© ì „)'] / 
                                    final_df['ì§€ê¸‰ì—¬ë ¥ê¸°ì¤€ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© ì „)'].replace(0, pd.NA)) * 100
        # ê²½ê³¼ì¡°ì¹˜ í›„
        final_df['ratio_after'] = (final_df['ì§€ê¸‰ì—¬ë ¥ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© í›„)'] / 
                                   final_df['ì§€ê¸‰ì—¬ë ¥ê¸°ì¤€ê¸ˆì•¡(ê²½ê³¼ì¡°ì¹˜ ì ìš© í›„)'].replace(0, pd.NA)) * 100
        
        # ì •ë ¬ (ë‚ ì§œìˆœ)
        final_df = final_df.sort_values('ê¸°ì¤€ë…„ì›”')
        
        return final_df
    except Exception as e:
        st.error(f"ë¶„ì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

def fetch_ecos_bond_yield(start_month, end_month):
    """ECOSì—ì„œ êµ­ê³ ì±„ 10ë…„ ê¸ˆë¦¬ ì¡°íšŒ"""
    ECOS_API_KEY = st.secrets.get("ECOS_API_KEY", "")
    if not ECOS_API_KEY:
        return pd.DataFrame()
    
    # K-ICS ë°ì´í„° ë²”ìœ„ì— ë§ì¶° ì‹œì‘/ì¢…ë£Œì¼ ì„¤ì •
    # start_month/end_month: '202303' í˜•ì‹ -> '20230301' / '20230331' ë“±ìœ¼ë¡œ ë³€í™˜ í•„ìš”í•˜ë‚˜
    # ECOSëŠ” ë‹¨ìˆœíˆ ì•ë’¤ ë‚ ì§œë§Œ ë„‰ë„‰íˆ ì£¼ë©´ ë¨
    start_date = f"{start_month}01"
    # í˜„ì¬ ë‚ ì§œ ê¸°ì¤€
    KST = timezone('Asia/Seoul')
    nowSeo = datetime.now(KST).strftime('%Y%m%d')
    
    bond_cd = '010210000' # êµ­ê³ ì±„ 10ë…„
    url = f'http://ecos.bok.or.kr/api/StatisticSearch/{ECOS_API_KEY}/json/kr/1/10000/817Y002/D/{start_date}/{nowSeo}/{bond_cd}'

    try:
        res = requests.get(url, timeout=10)
        data = res.json()
        if 'StatisticSearch' in data and 'row' in data['StatisticSearch']:
            rows = data['StatisticSearch']['row']
            df = pd.DataFrame(rows)
            df['yield'] = df['DATA_VALUE'].astype(float)
            # TIME: 20230301 -> ê¸°ì¤€ë…„ì›” 202303 ì¶”ì¶œ
            df['ê¸°ì¤€ë…„ì›”'] = df['TIME'].str[:6]
            
            # ì›”ë³„ ë§ˆì§€ë§‰ ì˜ì—…ì¼ ê¸°ì¤€ ê¸ˆë¦¬ ì¶”ì¶œ (K-ICS ëŒ€ë¹„ìš©)
            df_monthly = df.groupby('ê¸°ì¤€ë…„ì›”').last().reset_index()[['ê¸°ì¤€ë…„ì›”', 'yield']]
            return df_monthly
    except Exception as e:
        st.warning(f"ECOS ê¸ˆë¦¬ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    return pd.DataFrame()

def shorten_company_name(name):
    """íšŒì‚¬ëª…ì„ ë³´ê¸° ì¢‹ê²Œ ì¶•ì•½ (ì£¼ì‹íšŒì‚¬, (ì£¼), í•œêµ­ì§€ì  ë“± ì œê±°)"""
    if not name:
        return ""
    
    # ì œê±°í•  ë‹¨ì–´ ëª©ë¡
    removals = [
        "ì£¼ì‹íšŒì‚¬", "(ì£¼)", "ì£¼", 
        "ìƒëª…ë³´í—˜", "ì†í•´ë³´í—˜", "í™”ì¬í•´ìƒë³´í—˜", "í™”ì¬ë³´í—˜", "í•´ìƒë³´í—˜",
        "í•œêµ­ì§€ì "
    ]
    
    short_name = name
    for r in removals:
        short_name = short_name.replace(r, "")
    
    return short_name.strip()

def get_english_company_name(name):
    """ì°¨íŠ¸ í‘œì‹œìš© ì˜ë¬¸ íšŒì‚¬ëª… ë°˜í™˜"""
    if not name:
        return ""
    return CompKoEn.get(name, "")

def render_sector_chart(sector, filtered_df, company_df, color_sets, weighted_avg):
    """íŠ¹ì • ì—…ê¶Œì˜ ëˆ„ì  ë°” ì°¨íŠ¸ ë° í‰ê· ì„ ì„ ë Œë”ë§"""
    import pandas as pd
    from pyecharts import options as opts
    from pyecharts.charts import Bar
    from pyecharts.commons.utils import JsCode
    from streamlit_echarts import st_pyecharts

    st.write(f"### {sector}")
    
    # í•´ë‹¹ ì—…ê¶Œ ë°ì´í„° í•„í„°ë§ ë° ì •ë ¬
    s_df = filtered_df[filtered_df['êµ¬ë¶„'] == sector].sort_values('final_ratio', ascending=False)
    
    if s_df.empty:
        st.info(f"{sector} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ëˆ„ì  ì°¨íŠ¸ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
    base_ratios = [] # í•˜ë‹¨ (A)
    effect_ratios = [] # ìƒë‹¨ (D-A)
    total_ratios = [] # ë ˆì´ë¸” í‘œì‹œìš© (D)
    
    for _, row in s_df.iterrows():
        a_val = float(row['A'])
        d_val = float(row['final_ratio'])
        
        if row['is_fallback']:
            base_ratios.append(int(round(a_val, 0)))
            effect_ratios.append(0)
        else:
            base_ratios.append(int(round(a_val, 0)))
            effect_ratios.append(max(0, int(round(d_val - a_val, 0))))
        
        total_ratios.append(int(round(d_val, 0)))

    bar = Bar(init_opts=opts.InitOpts(width="100%", height="500px", theme="white", renderer="svg"))
    bar.add_xaxis(xaxis_data=s_df['short_display_name'].tolist())
    
    # 1. í•˜ë‹¨ ë°”: ê²½ê³¼ì¡°ì¹˜ ì „
    bar.add_yaxis(
        series_name="ê²½ê³¼ì¡°ì¹˜ ì „",
        y_axis=base_ratios,
        stack="stack1",
        label_opts=opts.LabelOpts(is_show=False),
        itemstyle_opts=opts.ItemStyleOpts(color=color_sets[sector][0])
    )
    
    # 2. ìƒë‹¨ ë°”: ê²½ê³¼ì¡°ì¹˜ íš¨ê³¼
    bar.add_yaxis(
        series_name="ê²½ê³¼ì¡°ì¹˜ íš¨ê³¼",
        y_axis=effect_ratios,
        stack="stack1",
        label_opts=opts.LabelOpts(
            is_show=True, 
            position="top", 
            formatter=JsCode("""function(params) {
                var total_ratios = """ + str(total_ratios) + """;
                return total_ratios[params.dataIndex] + '%';
            }""")
        ),
        itemstyle_opts=opts.ItemStyleOpts(color=color_sets[sector][1]),
        markline_opts=opts.MarkLineOpts(
            data=[{"yAxis": round(weighted_avg, 2), "name": f"ì—…ê¶Œ í‰ê·  ({round(weighted_avg, 1)}%)"}],
            label_opts=opts.LabelOpts(formatter=f"{sector} í‰ê· : {round(weighted_avg, 1)}%", position="insideEndTop"),
            linestyle_opts=opts.LineStyleOpts(type_="dashed", width=1, color="#D10000")
        )
    )
    
    bar.set_global_opts(
        title_opts=opts.TitleOpts(title=f"{sector}ì‚¬ë³„ K-ICS ë¹„ìœ¨"),
        xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=45, interval=0, font_size=11)),
        yaxis_opts=opts.AxisOpts(name="ë¹„ìœ¨ (%)", axislabel_opts=opts.LabelOpts(formatter="{value}%")),
        tooltip_opts=opts.TooltipOpts(
            trigger="axis", 
            axis_pointer_type="shadow",
            formatter=JsCode("""function(params) {
                var res = params[0].name + '<br/>';
                var total = 0;
                for(var i=0; i<params.length; i++) {
                    res += params[i].marker + params[i].seriesName + ': ' + params[i].value + '%<br/>';
                    total += params[i].value;
                }
                res += '<b>ìµœì¢… ë¹„ìœ¨ (ê²½ê³¼í›„): ' + total + '%</b>';
                return res;
            }""")
        ),
    )
    
    st_pyecharts(bar, height="500px", key=f"bar_{sector}", renderer="svg")

def get_available_months():
    """DBì— ì €ì¥ëœ ëª¨ë“  ê¸°ì¤€ë…„ì›” ëª©ë¡ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ë°˜í™˜"""
    conn = get_md_connection()
    if not conn:
        return []
    try:
        # ìµœì‹ ìˆœ ì •ë ¬
        df = conn.execute(f"SELECT DISTINCT ê¸°ì¤€ë…„ì›” FROM {TABLE_NAME} ORDER BY ê¸°ì¤€ë…„ì›” DESC").df()
        conn.close()
        return df['ê¸°ì¤€ë…„ì›”'].tolist()
    except Exception as e:
        st.error(f"ê¸°ì¤€ë…„ì›” ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

def load_company_solvency_data(target_month):
    """ë³´í—˜ì‚¬ë³„ íŠ¹ì • ê¸°ì¤€ë…„ì›” ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    if not target_month:
        return pd.DataFrame(), ""

    conn = get_md_connection()
    if not conn:
        return pd.DataFrame(), target_month
    
    try:
        # 1. í•„ìš”í•œ ê³„ì •ì½”ë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        # A, B, C, D, E, F (E, FëŠ” ê°€ì¤‘í‰ê·  ê³„ì‚°ìš© ë¶„ì/ë¶„ëª¨, B, CëŠ” Fallbackìš©)
        query = f"""
            SELECT êµ¬ë¶„, íšŒì‚¬ëª…, ê³„ì •ì½”ë“œ, ê°’, ê¸°ì¤€ë…„ì›”
            FROM {TABLE_NAME}
            WHERE ê¸°ì¤€ë…„ì›” = ? AND ê³„ì •ì½”ë“œ IN ('A', 'B', 'C', 'D', 'E', 'F')
        """
        df = conn.execute(query, [target_month]).df()
        conn.close()

        if df.empty:
            return pd.DataFrame(), target_month

        # 3. í”¼ë²—í•˜ì—¬ A, D ì»¬ëŸ¼ìœ¼ë¡œ ë¶„ë¦¬
        pdf = df.pivot_table(
            index=['êµ¬ë¶„', 'íšŒì‚¬ëª…', 'ê¸°ì¤€ë…„ì›”'],
            columns='ê³„ì •ì½”ë“œ',
            values='ê°’',
            aggfunc='first'
        ).reset_index()

        # ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸ ë° 0 ì±„ìš°ê¸°
        for c_code in ['A', 'B', 'C', 'D', 'E', 'F']:
            if c_code not in pdf.columns:
                pdf[c_code] = 0
            else:
                pdf[c_code] = pdf[c_code].fillna(0)

        # 4. ê°œë³„ íšŒì‚¬ Fallback ë¡œì§ ë° ìœ íš¨ ê¸ˆì•¡ ê³„ì‚°
        def process_row(row):
            # A, D ê¸°ë°˜ ìµœì¢… ë¹„ìœ¨ (ë‹¨ìˆœ í‘œì‹œìš©)
            # Dê°€ ìœ íš¨í•˜ê³  Aì™€ ë‹¤ë¥¸ ê²½ìš°ì—ë§Œ 'ê²½ê³¼í›„' ì‚¬ìš©
            if row['D'] > 0 and row['D'] != row['A']:
                final_r = row['D']
                is_fb = False
            else:
                final_r = row['A']
                is_fb = True
            
            # ê°€ì¤‘ í‰ê· ìš© ìœ íš¨ ê¸ˆì•¡ ê³„ì‚°
            # ë¶„ì(ì§€ê¸‰ì—¬ë ¥ê¸ˆì•¡): E > 0 ? E : B
            eff_num = row['E'] if row['E'] > 0 else row['B']
            # ë¶„ëª¨(ê¸°ì¤€ê¸ˆì•¡): F > 0 ? F : C
            eff_den = row['F'] if row['F'] > 0 else row['C']
            
            return pd.Series([final_r, is_fb, eff_num, eff_den])

        pdf[['final_ratio', 'is_fallback', 'eff_num', 'eff_den']] = pdf.apply(process_row, axis=1)

        # 5. í‘œì‹œìš© íšŒì‚¬ëª… ì²˜ë¦¬
        pdf['display_name'] = pdf.apply(
            lambda r: f"{shorten_company_name(r['íšŒì‚¬ëª…'])}*" if not r['is_fallback'] else shorten_company_name(r['íšŒì‚¬ëª…']),
            axis=1
        )

        # Downstream logic can use stable ASCII aliases regardless of locale/encoding.
        dim_cols = pdf.columns[:3].tolist()
        if len(dim_cols) >= 3:
            pdf['sector'] = pdf[dim_cols[0]]
            pdf['company_name'] = pdf[dim_cols[1]]
            pdf['base_month'] = pdf[dim_cols[2]]

        return pdf, target_month
    except Exception as e:
        st.error(f"íšŒì‚¬ë³„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame(), ""

def build_company_change_df(current_df, previous_df):
    """Create latest-vs-previous K-ICS deltas per company."""
    if current_df.empty or previous_df.empty:
        return pd.DataFrame()

    curr = current_df.copy()
    prev = previous_df.copy()

    for df in [curr, prev]:
        if 'sector' not in df.columns or 'company_name' not in df.columns:
            continue
        if 'A' not in df.columns:
            df['A'] = 0
        if 'D' not in df.columns:
            df['D'] = 0
        df['ratio_before'] = pd.to_numeric(df['A'], errors='coerce').fillna(0)
        # Keep "after" consistent with existing fallback rule when D is missing/invalid.
        df['ratio_after'] = df.apply(lambda r: r['D'] if pd.notnull(r['D']) and r['D'] > 0 else r['A'], axis=1)

    merged = curr[['sector', 'company_name', 'ratio_before', 'ratio_after']].merge(
        prev[['sector', 'company_name', 'ratio_before', 'ratio_after']],
        on=['sector', 'company_name'],
        suffixes=('_current', '_previous'),
        how='inner'
    )

    if merged.empty:
        return pd.DataFrame()

    merged['delta_before'] = merged['ratio_before_current'] - merged['ratio_before_previous']
    merged['delta_after'] = merged['ratio_after_current'] - merged['ratio_after_previous']
    return merged

def render_company_change_chart(change_df, sector, delta_col, chart_title, key_suffix):
    """Render a diverging horizontal bar chart for company-level deltas."""
    s_df = change_df[change_df['sector'] == sector].copy()
    if s_df.empty:
        st.info(f"No data in {sector} sector.")
        return

    s_df = s_df.sort_values(delta_col, ascending=False)
    if "english_name" in s_df.columns:
        s_df['display_name'] = s_df['english_name']
    else:
        s_df['display_name'] = s_df['company_name'].map(get_english_company_name).fillna("")
    s_df = s_df[s_df['display_name'].astype(str).str.strip() != ""].copy()
    if s_df.empty:
        st.info(f"No companies with English names in {sector} sector.")
        return

    x_names = s_df['display_name'].tolist()
    y_delta = [round(float(v), 1) for v in s_df[delta_col]]
    prev_col = "ratio_before_previous" if delta_col == "delta_before" else "ratio_after_previous"
    curr_col = "ratio_before_current" if delta_col == "delta_before" else "ratio_after_current"
    y_prev = [round(float(v), 2) for v in s_df[prev_col]]
    y_curr = [round(float(v), 2) for v in s_df[curr_col]]

    # Axis-break-like compression for extreme outliers so smaller changes stay visible.
    abs_delta = sorted([abs(v) for v in y_delta], reverse=True)
    apply_axis_break = False
    break_start = 0.0
    break_scale = 0.35
    if len(abs_delta) >= 2 and abs_delta[1] > 0:
        ratio_gap = abs_delta[0] / abs_delta[1]
        if ratio_gap >= 2.8 and abs_delta[0] >= 20:
            apply_axis_break = True
            break_start = round(max(8.0, abs_delta[1] * 1.15), 1)

    def compress_delta(v):
        if not apply_axis_break:
            return round(v, 3)
        sign = -1 if v < 0 else 1
        av = abs(v)
        if av <= break_start:
            return round(v, 3)
        return round(sign * (break_start + (av - break_start) * break_scale), 3)

    chart_points = [{"value": compress_delta(v), "actual": v} for v in y_delta]
    max_abs_for_axis = max(abs(compress_delta(v)) for v in y_delta) if y_delta else 1
    axis_pad = max(2.0, max_abs_for_axis * 0.08)
    axis_min = round(-(max_abs_for_axis + axis_pad), 2)
    axis_max = round(max_abs_for_axis + axis_pad, 2)

    bar = Bar(init_opts=opts.InitOpts(width="100%", height="520px", theme="white", renderer="svg"))
    bar.add_xaxis(xaxis_data=x_names)
    bar.add_yaxis(
        series_name="Delta (latest-previous, %p)",
        y_axis=chart_points,
        label_opts=opts.LabelOpts(
            is_show=True,
            position="right",
            formatter=JsCode(
                "function(p){"
                "var raw=(p.data && p.data.actual!==undefined)?p.data.actual:p.value;"
                "return (raw > 0 ? '+' : '') + Number(raw).toFixed(1) + '%p';"
                "}"
            )
        ),
        itemstyle_opts=opts.ItemStyleOpts(
            color=JsCode(
                """
            function(params){
                var raw=(params.data && params.data.actual!==undefined)?params.data.actual:params.value;
                if(raw > 0){return '#1a9850';}
                if(raw < 0){return '#d73027';}
                return '#7f8c8d';
            }
            """
            )
        )
    )
    bar.reversal_axis()
    bar.set_global_opts(
        title_opts=opts.TitleOpts(title=chart_title, top=8),
        legend_opts=opts.LegendOpts(top=40),
        grid_opts=opts.GridOpts(left="34%", right="8%", top=96, bottom=28, contain_label=False),
        xaxis_opts=opts.AxisOpts(
            name="Delta (%p)",
            min_=axis_min,
            max_=axis_max,
            axislabel_opts=opts.LabelOpts(
                formatter=JsCode(
                    "function(v){"
                    f"var hasBreak={str(apply_axis_break).lower()};"
                    f"var b={break_start};"
                    f"var c={break_scale};"
                    "if(!hasBreak){return Number(v).toFixed(1);}"
                    "var s=v<0?-1:1; var a=Math.abs(v);"
                    "if(a<=b){return Number(v).toFixed(1);}"
                    "var restored=s*(b+((a-b)/c));"
                    "return Number(restored).toFixed(1);"
                    "}"
                )
            )
        ),
        yaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(font_size=11)),
        tooltip_opts=opts.TooltipOpts(
            trigger="item",
            formatter=JsCode(
                "function(p){"
                f"var prev={json.dumps(y_prev)}; var curr={json.dumps(y_curr)};"
                "var d=(p.data && p.data.actual!==undefined)?p.data.actual:p.value; var sign=d>0?'+':'';"
                "return p.name + '<br/>Previous: ' + prev[p.dataIndex] + '%<br/>Latest: ' + curr[p.dataIndex] + '%<br/><b>Delta: ' + sign + Number(d).toFixed(1) + '%p</b>';"
                "}"
            )
        ),
    )

    if apply_axis_break:
        bar.set_series_opts(
            markline_opts=opts.MarkLineOpts(
                data=[
                    opts.MarkLineItem(x=0),
                    opts.MarkLineItem(x=compress_delta(break_start)),
                    opts.MarkLineItem(x=compress_delta(-break_start)),
                ]
            )
        )
        st.caption(
            f"Axis compression applied: |delta| >= {break_start:.1f}%p is shown at {break_scale:.2f}x scale."
        )
    else:
        bar.set_series_opts(markline_opts=opts.MarkLineOpts(data=[opts.MarkLineItem(x=0)]))

    st_pyecharts(bar, height="520px", key=f"company_change_{key_suffix}_{sector}", renderer="svg")


def reclassify_company_sector(sector, company_name):
    """Classify non-life rows into non-life/reinsurance/excluded buckets."""
    if sector == 'ìƒëª…ë³´í—˜':
        return 'ìƒëª…ë³´í—˜'
    if sector == 'ì†í•´ë³´í—˜':
        if company_name in REINSURANCE_COMPANIES:
            return 'ì¬ë³´í—˜'
        if company_name in EXCLUDE_NON_LIFE:
            return 'ì œì™¸'
        return 'ì†í•´ë³´í—˜'
    return sector

def apply_sector_reclassification(df):
    """Apply consistent sector classification for company-level charts."""
    if df.empty or 'sector' not in df.columns or 'company_name' not in df.columns:
        return df

    out = df.copy()
    out['sector'] = out.apply(lambda r: reclassify_company_sector(r['sector'], r['company_name']), axis=1)
    out = out[out['sector'] != 'ì œì™¸'].copy()
    return out

# ë¶„ì„ìš© ì—…ê¶Œ ë¶„ë¥˜ ì„¤ì • (ì†í•´ ì—…ê¶Œ ì„¸ë¶„í™”ìš©)
EXCLUDE_NON_LIFE = [
    'íŒ©í† ë¦¬ë®¤ì¶”ì–¼ì¸ìŠˆëŸ°ìŠ¤ì»´í¼ë‹ˆ í•œêµ­ì§€ì ',
    'í¼ìŠ¤íŠ¸ì–´ë©”ë¦¬ì¹¸ê¶Œì›ë³´í—˜(ì£¼)í•œêµ­ì§€ì ',
    'ë¯¸ì“°ì´ìŠ¤ë¯¸í† ëª¨í•´ìƒí™”ì¬ë³´í—˜(ì£¼)í•œêµ­ì§€ì ',
    'ìŠ¤íƒ€ì¸í„°ë‚´ì…”ë„ì¸ìŠˆì–´ëŸ°ìŠ¤ì‹±ê°€í¬ë¥´í•œêµ­ì§€ì ',
    'ë™ê²½í•´ìƒì¼ë™í™”ì¬ë³´í—˜(ì£¼)ì„œìš¸ì§€ì [í]',
    'ì„œìš¸ë³´ì¦ë³´í—˜ì£¼ì‹íšŒì‚¬',
    'ë§ˆì´ë¸Œë¼ìš´ë°˜ë ¤ë™ë¬¼ì „ë¬¸ë³´í—˜',
    'ì•Œë¦¬ì•ˆì¸ ê¸€ë¡œë²Œì½”í¼ë ˆì´íŠ¸ì•¤ìŠ¤í˜ì…œí‹°ì—ìŠ¤ì´ í•œêµ­ì§€ì '
]

REINSURANCE_COMPANIES = [
    'ì•Œì§€ì—ì´ ë¦¬ì¸ìŠˆì–´ëŸ°ìŠ¤ ì»´íŒŒë‹ˆ í•œêµ­ì§€ì ',
    'ì½”ë¦¬ì•ˆë¦¬ì¬ë³´í—˜ì£¼ì‹íšŒì‚¬',
    'ìŠ¤ìœ„ìŠ¤ë¦¬ ì•„ì‹œì•„ í”¼í‹°ì´ ì—˜í‹°ë”” í•œêµ­ì§€ì ',
    'ìŠ¤ì½”ë¦¬ì¸ìŠˆì–´ëŸ°ìŠ¤ì•„ì‹œì•„í¼ì‹œí”½í”¼í‹°ì´ì—˜í‹°ë””í•œêµ­ì§€ì ',
    'ë®Œí—¨ì¬ë³´í—˜ì£¼ì‹íšŒì‚¬ í•œêµ­ì§€ì ',
    'ì œë„ˆëŸ´ì¬ë³´í—˜ì£¼ì‹íšŒì‚¬ ì„œìš¸ì§€ì ',
    'í¼ì‹œí”½ë¼ì´í”„ë¦¬ ì¸í„°ë‚´ì…”ë„ í•œêµ­ì§€ì ',
    'í•˜ë…¸ë²„ì¬ë³´í—˜(ì£¼) í•œêµ­ì§€ì '
]

# ==========================================
# 2. ë¹„ë™ê¸° í†µì‹  í•¨ìˆ˜ ì •ì˜
# ==========================================
async def fetch_json(session, url, params):
    try:
        async with session.get(url, params=params, timeout=10) as response:
            if response.status == 200:
                text = await response.text()
                try:
                    return json.loads(text)
                except json.JSONDecodeError:
                    return None
            else:
                return None
    except Exception:
        return None

async def get_companies(session, part_div):
    """ê¸ˆìœµíšŒì‚¬ ì½”ë“œ ì¡°íšŒ"""
    url = f"{BASE_URL}/companySearch.json"
    params = {"lang": "kr", "auth": API_KEY, "partDiv": part_div}
    data = await fetch_json(session, url, params)

    company_list = []
    if data and 'result' in data and 'list' in data['result']:
        for item in data['result']['list']:
            company_list.append({
                'financeCd': item['finance_cd'],
                'financeNm': item['finance_nm'],
                'partDiv': part_div
            })
    return company_list

async def get_accounts(session, list_no):
    """ê³„ì •í•­ëª© ì¡°íšŒ"""
    url = f"{BASE_URL}/accountListSearch.json"
    params = {"lang": "kr", "auth": API_KEY, "listNo": list_no}
    data = await fetch_json(session, url, params)

    account_list = []
    if data and 'result' in data and 'list' in data['result']:
        for item in data['result']['list']:
            account_list.append({
                'accountCd': item['account_cd'],
                'accountNm': item['account_nm'],
                'listNo': list_no
            })
    return account_list

async def fetch_statistics(session, semaphore, company, account, pbar, status_text):
    """í†µê³„ì •ë³´ ìˆ˜ì§‘"""
    url = f"{BASE_URL}/statisticsInfoSearch.json"
    params = {
        "lang": "kr",
        "auth": API_KEY,
        "financeCd": company['financeCd'],
        "listNo": account['listNo'],
        "accountCd": account['accountCd'],
        "term": TERM,
        "startBaseMm": TARGET_MONTH,
        "endBaseMm": TARGET_MONTH
    }

    async with semaphore:
        data = await fetch_json(session, url, params)
    
    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (UI) - ë„ˆë¬´ ì¦ì€ ì—…ë°ì´íŠ¸ëŠ” ì„±ëŠ¥ ì €í•˜ë¥¼ ìœ ë°œí•˜ë¯€ë¡œ ì£¼ì˜
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ë¡œì§ë§Œ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ ë°˜í™˜

    if data and 'result' in data and 'list' in data['result']:
        result_list = data['result']['list']
        if result_list:
            item = result_list[0]
            # ê°’ ìš°ì„ ìˆœìœ„ í™•ì¸
            raw_value = item.get('a') or item.get('won') or item.get('column_value') or 0

            return {
                'êµ¬ë¶„': 'ìƒëª…ë³´í—˜' if company['partDiv'] == 'H' else 'ì†í•´ë³´í—˜',
                'íšŒì‚¬ì½”ë“œ': company['financeCd'],
                'íšŒì‚¬ëª…': company['financeNm'],
                'ê³„ì •ì½”ë“œ': account['accountCd'],
                'ê³„ì •ëª…': account['accountNm'],
                'ê¸°ì¤€ë…„ì›”': TARGET_MONTH, # API ê²°ê³¼ì™€ ìƒê´€ì—†ì´ ìš”ì²­í•œ ê¸°ì¤€ë…„ì›”ë¡œ ì €ì¥ (ì¼ê´€ì„± ìœ ì§€)
                'ë‹¨ìœ„': item.get('unit_name', ''),
                'ê°’': raw_value
            }
    return None

# ==========================================
# 3. ë©”ì¸ ì‹¤í–‰ ë¡œì§ (Async Wrapper)
# ==========================================
async def run_async_collection():
    status_container = st.status("ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ë° ìºì‹œ í™•ì¸ ì¤‘...", expanded=True)
    
    try:
        # 0. MotherDuck ìºì‹œ í™•ì¸
        status_container.write(f"ğŸ” {TARGET_MONTH} ë°ì´í„° ìºì‹œ í™•ì¸ ì¤‘...")
        cached_df = get_cached_data(TARGET_MONTH)
        
        if not cached_df.empty:
            status_container.write(f"âœ… {len(cached_df)}ê±´ì˜ ë°ì´í„°ë¥¼ MotherDuckì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        else:
            status_container.write("â„¹ï¸ í•´ë‹¹ ì›”ì˜ ìºì‹œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        async with aiohttp.ClientSession() as session:
            # 1. ëª©ë¡ ì¡°íšŒ
            status_container.write("ğŸ” 1. ê¸ˆìœµíšŒì‚¬ ë° ê³„ì •í•­ëª© ëª©ë¡ ì¡°íšŒ ì¤‘...")
            
            # ë³‘ë ¬ë¡œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            f1 = get_companies(session, 'H')
            f2 = get_companies(session, 'I')
            f3 = get_accounts(session, 'SH021')
            f4 = get_accounts(session, 'SI021')
            
            life_companies, non_life_companies, life_accounts, non_life_accounts = await asyncio.gather(f1, f2, f3, f4)
            
            total_companies = len(life_companies) + len(non_life_companies)
            status_container.write(f"âœ… íšŒì‚¬ ëª©ë¡ í™•ë³´: ì´ {total_companies}ê°œ")

            # 2. ì‘ì—… ìƒì„± (ìºì‹œì— ì—†ëŠ” ê²ƒë§Œ)
            tasks = []
            semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
            
            status_container.write("ğŸ“¦ 2. ë¯¸ìˆ˜ì§‘ ë°ì´í„° í™•ì¸ ë° ìš”ì²­ ìƒì„± ì¤‘...")
            # ê¸°ì¡´ ë°ì´í„° í‚¤ ìƒì„± (íšŒì‚¬ì½”ë“œ, ê³„ì •ì½”ë“œ)
            existing_keys = set()
            if not cached_df.empty:
                # ë°ì´í„° íƒ€ì…ì„ ë¬¸ìì—´ë¡œ ê°•ì œ ë³€í™˜ ë° ê³µë°± ì œê±° (ìºì‹œ ë¯¸ìŠ¤ ë°©ì§€)
                existing_keys = set(zip(
                    cached_df['íšŒì‚¬ì½”ë“œ'].astype(str).str.strip(), 
                    cached_df['ê³„ì •ì½”ë“œ'].astype(str).str.strip()
                ))

            def build_tasks(companies, accounts):
                for comp in companies:
                    for acc in accounts:
                        # ë¹„êµ ì‹œì—ë„ ë¬¸ìì—´ë¡œ ë³€í™˜ ë° ê³µë°± ì œê±°
                        f_cd = str(comp['financeCd']).strip()
                        a_cd = str(acc['accountCd']).strip()
                        if (f_cd, a_cd) not in existing_keys:
                            tasks.append(fetch_statistics(session, semaphore, comp, acc, None, None))

            build_tasks(life_companies, life_accounts)
            build_tasks(non_life_companies, non_life_accounts)

            total_tasks = len(tasks)
            
            if total_tasks == 0:
                status_container.write("âœ¨ ëª¨ë“  ë°ì´í„°ê°€ ì´ë¯¸ ìºì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                status_container.update(label="âœ… ìºì‹œ ë°ì´í„° ë¦¬ë¡œë“œ ì™„ë£Œ!", state="complete", expanded=False)
                return cached_df.to_dict('records')

            status_container.write(f"ğŸ“¡ {len(existing_keys)}ê±´ì€ ìºì‹œì—ì„œ ë°œê²¬í–ˆê³ , {total_tasks} ê±´ì˜ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ APIë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")

            # 3. ì‹¤í–‰ ë° ì§„í–‰ë¥  í‘œì‹œ
            new_results = []
            progress_bar = status_container.progress(0)
            completed_count = 0
            
            for f in asyncio.as_completed(tasks):
                res = await f
                if res:
                    new_results.append(res)
                
                completed_count += 1
                if total_tasks > 0:
                    progress_bar.progress(completed_count / total_tasks)

            # 4. ìƒˆë¡œìš´ ë°ì´í„° DB ì €ì¥
            if new_results:
                status_container.write(f"ğŸ’¾ {len(new_results)}ê±´ì˜ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ MotherDuckì— ì €ì¥ ì¤‘...")
                new_df = pd.DataFrame(new_results)
                # ê°’ ì „ì²˜ë¦¬ (ì €ì¥ ì „ ìˆ«ìë¡œ ë³€í™˜)
                new_df['ê°’'] = pd.to_numeric(new_df['ê°’'].astype(str).str.replace(',', ''), errors='coerce')
                save_to_md(new_df)
                
                # ê¸°ì¡´ ë°ì´í„°ì™€ í•©ì¹˜ê¸°
                if not cached_df.empty:
                    # ì»¬ëŸ¼ ìˆœì„œ ë° ì´ë¦„ ì¼ê´€ì„± í™•ë³´
                    all_results_df = pd.concat([cached_df[COLUMNS], new_df[COLUMNS]], ignore_index=True)
                    results = all_results_df.to_dict('records')
                else:
                    results = new_results
            else:
                results = cached_df.to_dict('records')

            status_container.update(label="âœ… ë°ì´í„° ìˆ˜ì§‘ ë° ìºì‹± ì™„ë£Œ!", state="complete", expanded=False)
            return results

    except Exception as e:
        status_container.update(label="âš ï¸ ì˜¤ë¥˜ ë°œìƒ", state="error")
        st.error(f"ì˜¤ë¥˜ ìƒì„¸: {e}")
        return []

# ==========================================
# 4. Streamlit UI êµ¬ì„±
# ==========================================
st.title("ğŸ“Š ë³´í—˜ì‚¬ ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# ë©”ì¸ íƒ­ ë¶„ë¦¬: ë¶„ì„ ëŒ€ì‹œë³´ë“œ, íšŒì‚¬ë³„ í˜„í™©, ë°ì´í„° ìˆ˜ì§‘ê¸°
selected_tab = st.segmented_control(
    "ë©”ë‰´ ì„ íƒ",
    ["ğŸ“ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (Dashboard)", "ğŸ“Š íšŒì‚¬ë³„ í˜„í™© (Company Status)", "ğŸ“‰ íšŒì‚¬ë³„ ë³€ë™ (Company Change)", "ğŸ“¡ ë°ì´í„° ìˆ˜ì§‘ê¸° (Collector)"],
    default="ğŸ“ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (Dashboard)",
    label_visibility="collapsed"
)

if selected_tab == "ğŸ“ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (Dashboard)":
    st.subheader("ğŸ“Š K-ICS ë¹„ìœ¨ ì¶”ì´ ë¶„ì„")
    st.info("MotherDuckì— ì €ì¥ëœ ëª¨ë“  ê³¼ê±° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œê³„ì—´ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    
    analysis_df = load_kics_analysis_data()
    
    if not analysis_df.empty:
        # EChartsìš© ë°ì´í„° ì¤€ë¹„
        x_data = sorted(analysis_df['ê¸°ì¤€ë…„ì›”'].unique().tolist())
        
        # ê¸ˆë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        min_month = analysis_df['ê¸°ì¤€ë…„ì›”'].min()
        max_month = analysis_df['ê¸°ì¤€ë…„ì›”'].max()
        bond_df = fetch_ecos_bond_yield(min_month, max_month)
        
        # ê¸ˆë¦¬ ë°ì´í„° ì‹±í¬ ë§ì¶”ê¸°
        if not bond_df.empty:
            kics_months = analysis_df['ê¸°ì¤€ë…„ì›”'].unique()
            bond_df = bond_df[bond_df['ê¸°ì¤€ë…„ì›”'].isin(kics_months)].sort_values('ê¸°ì¤€ë…„ì›”')
        
        # pyecharts Line ê°ì²´ ìƒì„±
        line = Line(init_opts=opts.InitOpts(width="100%", height="600px", theme="white", renderer="svg"))
        line.add_xaxis(xaxis_data=x_data)
        
        # ìƒ‰ìƒ ë§¤í•‘
        colors = {
            'ìƒëª…ë³´í—˜': '#1f77b4',
            'ì†í•´ë³´í—˜': '#ff7f0e',
            'ì „ì²´': '#2ca02c'
        }
        
        for g in ['ìƒëª…ë³´í—˜', 'ì†í•´ë³´í—˜', 'ì „ì²´']:
            # xì¶• ìˆœì„œì— ë§ì¶° ì •ë ¬ ë° ëˆ„ë½ê°’ ì²˜ë¦¬
            g_df = analysis_df[analysis_df['êµ¬ë¶„'] == g].set_index('ê¸°ì¤€ë…„ì›”').reindex(x_data).reset_index()
            
            # ê²½ê³¼ì¡°ì¹˜ í›„ (ì‹¤ì„ )
            line.add_yaxis(
                series_name=f"{g} (ê²½ê³¼ì¡°ì¹˜ í›„)",
                y_axis=[round(float(v), 2) if pd.notnull(v) else None for v in g_df['ratio_after']],
                symbol="circle",
                symbol_size=10,
                linestyle_opts=opts.LineStyleOpts(width=4, color=colors[g]),
                itemstyle_opts=opts.ItemStyleOpts(color=colors[g]),
                label_opts=opts.LabelOpts(is_show=False),
                is_smooth=False,
            )
            
            # ê²½ê³¼ì¡°ì¹˜ ì „ (ì ì„ , ì´ˆê¸° ë¹„í™œì„±í™”)
            line.add_yaxis(
                series_name=f"{g} (ê²½ê³¼ì¡°ì¹˜ ì „)",
                y_axis=[round(float(v), 2) if pd.notnull(v) else None for v in g_df['ratio_before']],
                symbol="circle",
                                symbol_size=8,
                linestyle_opts=opts.LineStyleOpts(width=2, type_="dashed", color=colors[g]),
                itemstyle_opts=opts.ItemStyleOpts(color=colors[g]),
                label_opts=opts.LabelOpts(is_show=False),
                is_smooth=False,
            )
            
        # ë³´ì¡°ì¶• ì¶”ê°€ (ê¸ˆë¦¬ìš©)
        line.extend_axis(
            yaxis=opts.AxisOpts(
                name="ê¸ˆë¦¬ (%)",
                type_="value",
                position="right",
                is_scale=True, # ë°ì´í„° ë²”ìœ„ì— ë§ì¶° ìœ ë™ì  ì¡°ì •
                axislabel_opts=opts.LabelOpts(formatter="{value}%"),
                splitline_opts=opts.SplitLineOpts(is_show=False),
            )
        )
        
        if not bond_df.empty:
            b_df = bond_df.set_index('ê¸°ì¤€ë…„ì›”').reindex(x_data).reset_index()
            line.add_yaxis(
                series_name="êµ­ê³ ì±„ 10ë…„ (ìš°ì¶•)",
                y_axis=[round(float(v), 3) if pd.notnull(v) else None for v in b_df['yield']],
                yaxis_index=1,
                symbol="diamond",
                symbol_size=12,
                linestyle_opts=opts.LineStyleOpts(width=2, type_="dashed", color="#6e7074"),
                itemstyle_opts=opts.ItemStyleOpts(color="#6e7074"),
                label_opts=opts.LabelOpts(is_show=False),
            )
            
        # ì´ˆê¸° ë¹„í™œì„±í™”í•  ì‹œë¦¬ì¦ˆ ë§µ ìƒì„±
        selected_map = {f"{g} (ê²½ê³¼ì¡°ì¹˜ ì „)": False for g in ['ìƒëª…ë³´í—˜', 'ì†í•´ë³´í—˜', 'ì „ì²´']}
        
        line.set_global_opts(
            title_opts=opts.TitleOpts(title="ë³´í—˜ì—…ê¶Œë³„ K-ICS ë¹„ìœ¨ ë° êµ­ê³ ì±„ 10ë…„ ê¸ˆë¦¬ ì¶”ì´", subtitle="ê¸°ì¤€ë…„ì›”ë³„ í˜„í™©"),
            tooltip_opts=opts.TooltipOpts(trigger="axis", axis_pointer_type="cross"),
            xaxis_opts=opts.AxisOpts(name="ê¸°ì¤€ë…„ì›”", type_="category", boundary_gap=True),
            yaxis_opts=opts.AxisOpts(
                name="K-ICS ë¹„ìœ¨ (%)",
                is_scale=True, # ë°ì´í„° ë²”ìœ„ì— ë§ì¶° ìœ ë™ì  ì¡°ì •
                axislabel_opts=opts.LabelOpts(formatter="{value}%"),
                splitline_opts=opts.SplitLineOpts(is_show=True),
            ),
            legend_opts=opts.LegendOpts(
                pos_right="5%", 
                pos_top="5%",
                orient="vertical", # ì°¨íŠ¸ ë‚´ë¶€ ê°€ë…ì„±ì„ ìœ„í•´ ì„¸ë¡œ ë°°ì¹˜
                selected_map=selected_map,
                background_color="rgba(255,255,255,0.7)", # ì•½ê°„ì˜ ë°°ê²½ íˆ¬ëª…ë„
                border_color="#ccc"
            ),
            datazoom_opts=[
                opts.DataZoomOpts(range_start=0, range_end=100), 
                opts.DataZoomOpts(type_="inside", range_start=0, range_end=100)
            ],
            toolbox_opts=opts.ToolboxOpts(is_show=True),
        )
        
        st_pyecharts(line, height="600px", key="dashboard_line_chart", renderer="svg")
        
        with st.expander("ğŸ“ ìƒì„¸ ìˆ˜ì¹˜ ë°ì´í„° í™•ì¸"):
            st.dataframe(analysis_df, width="stretch")
    else:
        st.warning("í‘œì‹œí•  ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ë°ì´í„° ìˆ˜ì§‘ê¸°' íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ ì£¼ì„¸ìš”.")
        
        # ë””ë²„ê¹…ì„ ìœ„í•œ ë°ì´í„° í˜„í™© ì„¸ì…˜ (Dashboardì—ì„œë„ ë°ì´í„°ê°€ ì—†ì„ ë•Œ í‘œì‹œ)
        with st.expander("ğŸ› ï¸ ë°ì´í„°ë² ì´ìŠ¤ í˜„í™© í™•ì¸ (ë””ë²„ê¹…)"):
            conn = get_md_connection()
            if conn:
                try:
                    count = conn.execute(f"SELECT COUNT(*) FROM {TABLE_NAME}").fetchone()[0]
                    st.write(f"í˜„ì¬ ì´ ë ˆì½”ë“œ ìˆ˜: {count}ê±´")
                    
                    st.write("ë³´ê´€ ì¤‘ì¸ ê³„ì •ëª… ëª©ë¡:")
                    distinct_accounts = conn.execute(f"SELECT DISTINCT ê³„ì •ëª… FROM {TABLE_NAME}").df()
                    st.dataframe(distinct_accounts, width="stretch")
                    
                    st.write("ë³´ê´€ ì¤‘ì¸ ê¸°ì¤€ë…„ì›” ëª©ë¡:")
                    distinct_months = conn.execute(f"SELECT DISTINCT ê¸°ì¤€ë…„ì›” FROM {TABLE_NAME} ORDER BY ê¸°ì¤€ë…„ì›”").df()
                    st.dataframe(distinct_months, width="stretch")
                    
                    conn.close()
                except Exception as e:
                    st.error(f"í˜„í™© í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            else:
                st.warning("MotherDuck ì—°ê²° ì‹¤íŒ¨ (í† í° í™•ì¸ í•„ìš”)")

elif selected_tab == "ğŸ“Š íšŒì‚¬ë³„ í˜„í™© (Company Status)":
    st.subheader("ğŸ“Š íšŒì‚¬ë³„ ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨ í˜„í™©")
    
    # ê°€ìš©í•œ ëª¨ë“  ê¸°ì¤€ë…„ì›” ê°€ì ¸ì˜¤ê¸°
    available_months = get_available_months()
    
    if available_months:
        # ê¸°ì¤€ë…„ì›” ì„ íƒ ì˜ì—­
        col_m, col_e = st.columns([1, 2])
        with col_m:
            selected_month = st.selectbox(
                "ğŸ“… ê¸°ì¤€ë…„ì›” ì„ íƒ", 
                options=available_months, 
                index=0,
                help="ì¡°íšŒí•  ê¸°ì¤€ë…„ì›”ì„ ì„ íƒí•˜ì„¸ìš”. ìµœì‹  ë°ì´í„°ê°€ ìƒë‹¨ì— ìœ„ì¹˜í•©ë‹ˆë‹¤."
            )
        
        company_df, latest_m = load_company_solvency_data(selected_month)
    
        if not company_df.empty:
            # ì—…ê¶Œ ì¬ë¶„ë¥˜ ë¡œì§ (ì†í•´ë³´í—˜ ì„¸ë¶„í™”)
            def reclassify_sector(row):
                if row['êµ¬ë¶„'] == 'ìƒëª…ë³´í—˜':
                    return 'ìƒëª…ë³´í—˜'
                elif row['êµ¬ë¶„'] == 'ì†í•´ë³´í—˜':
                    if row['íšŒì‚¬ëª…'] in REINSURANCE_COMPANIES:
                        return 'ì¬ë³´í—˜'
                    elif row['íšŒì‚¬ëª…'] in EXCLUDE_NON_LIFE:
                        return 'ì œì™¸'
                    else:
                        return 'ì†í•´ë³´í—˜'
                return row['êµ¬ë¶„']

            company_df['êµ¬ë¶„'] = company_df.apply(reclassify_sector, axis=1)
            # ì œì™¸ ëŒ€ìƒ ì œê±°
            company_df = company_df[company_df['êµ¬ë¶„'] != 'ì œì™¸'].copy()

            # ì˜ë¬¸ëª… ë§¤í•‘ ê²€ì¦ (ëˆ„ë½ì´ ìˆìœ¼ë©´ ì°¨íŠ¸ ë Œë”ë§ ì¤‘ë‹¨)
            missing_companies = sorted([c for c in company_df['íšŒì‚¬ëª…'].unique().tolist() if c not in CompKoEn])
            if missing_companies:
                st.error(
                    f"ì˜ë¬¸ íšŒì‚¬ëª… ë§¤í•‘ ëˆ„ë½: {len(missing_companies)}ê°œ íšŒì‚¬. "
                    "ëˆ„ë½ ë°©ì§€ë¥¼ ìœ„í•´ ì°¨íŠ¸ ë Œë”ë§ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤. CompKoEnì— ì•„ë˜ íšŒì‚¬ë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”."
                )
                st.dataframe(pd.DataFrame({'ëˆ„ë½ íšŒì‚¬ëª…': missing_companies}), width="stretch")
                st.stop()

            st.markdown(f"**ì¡°íšŒ ì‹œì : {latest_m}** ( * í‘œì‹œ: ê²½ê³¼ì¡°ì¹˜ ì ìš© í›„ ë¹„ìœ¨ ì‚¬ìš© )")
            
            # ì œì™¸í•  íšŒì‚¬ ì„ íƒ UI
            all_companies = sorted(company_df['íšŒì‚¬ëª…'].unique().tolist())
            excluded_companies = st.multiselect(
                "ğŸ“Š ë¹„êµ ë¶„ì„ì—ì„œ ì œì™¸í•  íšŒì‚¬ ì„ íƒ (ì„ íƒ ì‹œ ì°¨íŠ¸ì—ì„œ ì œê±°ë©ë‹ˆë‹¤)",
                options=all_companies,
                default=[],
                help="ë°ì´í„°ê°’ì´ ë¹„ì •ìƒì ìœ¼ë¡œ í¬ê±°ë‚˜ ì‘ì•„ ì°¨íŠ¸ì˜ ì „ì²´ í˜•íƒœë¥¼ ì™œê³¡í•˜ëŠ” íšŒì‚¬ë¥¼ ì œì™¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
            
            # í•„í„°ë§ ì ìš©
            filtered_df = company_df[~company_df['íšŒì‚¬ëª…'].isin(excluded_companies)].copy()
            
            # íšŒì‚¬ëª… ì˜ë¬¸ëª… ì ìš© (ì‹œê°í™”ìš©)
            filtered_df['short_display_name'] = filtered_df.apply(
                lambda r: f"{get_english_company_name(r['íšŒì‚¬ëª…'])}*" if not r['is_fallback'] else get_english_company_name(r['íšŒì‚¬ëª…']),
                axis=1
            )
            
            # ìƒ‰ìƒ ì„¤ì • (ì—°í•œ ìƒ‰, ì§„í•œ ìƒ‰)
            color_sets = {
                'ìƒëª…ë³´í—˜': ['#A6CEE3', '#1F78B4'], 
                'ì†í•´ë³´í—˜': ['#FDBF6F', '#FF7F00'],
                'ì¬ë³´í—˜': ['#B2DF8A', '#33A02C']  # ì—°í•œ ì´ˆë¡, ì§„í•œ ì´ˆë¡
            }

            # ì°¨íŠ¸ ë Œë”ë§ ë¡œì§ (ìƒë‹¨ 2ì—´: ìƒëª…/ì†í•´, í•˜ë‹¨ 1ì—´: ì¬ë³´í—˜)
            col_l, col_r = st.columns(2)
            for i, sector in enumerate(['ìƒëª…ë³´í—˜', 'ì†í•´ë³´í—˜']):
                target_col = col_l if i == 0 else col_r
                with target_col:
                    sector_df = company_df[company_df['êµ¬ë¶„'] == sector]
                    sum_num = sector_df['eff_num'].sum()
                    sum_den = sector_df['eff_den'].sum()
                    weighted_avg = (sum_num / sum_den * 100) if sum_den > 0 else 0
                    
                    render_sector_chart(sector, filtered_df, company_df, color_sets, weighted_avg)
            
            st.divider()
            # ì¬ë³´í—˜ ì°¨íŠ¸ (ìƒë‹¨ ì°¨íŠ¸ì™€ widthë¥¼ ë§ì¶”ê¸° ìœ„í•´ 2ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ ì‚¬ìš©)
            col_re, col_empty = st.columns(2)
            with col_re:
                sector = 'ì¬ë³´í—˜'
                sector_df = company_df[company_df['êµ¬ë¶„'] == sector]
                sum_num = sector_df['eff_num'].sum()
                sum_den = sector_df['eff_den'].sum()
                weighted_avg = (sum_num / sum_den * 100) if sum_den > 0 else 0
                render_sector_chart(sector, filtered_df, company_df, color_sets, weighted_avg)
            
            with st.expander("ğŸ“ ìƒì„¸ ë°ì´í„° í™•ì¸"):
                # í‘œì‹œìš© ë°ì´í„°í”„ë ˆì„ êµ¬ì„±
                display_df = filtered_df.copy()
                display_df['ì˜ë¬¸íšŒì‚¬ëª…'] = display_df['íšŒì‚¬ëª…'].map(get_english_company_name)
                # A, D ì»¬ëŸ¼ì´ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                for col in ['A', 'D']:
                    if col not in display_df.columns:
                        display_df[col] = 0
                
                st.dataframe(display_df[['êµ¬ë¶„', 'íšŒì‚¬ëª…', 'ì˜ë¬¸íšŒì‚¬ëª…', 'D', 'A', 'final_ratio', 'is_fallback']].rename(
                    columns={
                        'D': 'ë¹„ìœ¨(ê²½ê³¼í›„)', 
                        'A': 'ë¹„ìœ¨(ê²½ê³¼ì „)',
                        'final_ratio': 'ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨(%)', 
                        'is_fallback': 'ê²½ê³¼ì „ì‚¬ìš©ì—¬ë¶€'
                    }
                ), width="stretch")
        else:
            st.warning(f"{selected_month}ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„° ìˆ˜ì§‘ì„ ì§„í–‰í•´ ì£¼ì„¸ìš”.")
    else:
        st.warning("í‘œì‹œí•  íšŒì‚¬ë³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ë°ì´í„° ìˆ˜ì§‘ê¸°' íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•´ ì£¼ì„¸ìš”.")

elif selected_tab == "ğŸ“‰ íšŒì‚¬ë³„ ë³€ë™ (Company Change)":
    st.subheader("ğŸ“‰ íšŒì‚¬ë³„ K-ICS ë³€ë™ (ìµœê·¼ ë¶„ê¸° vs ì§ì „ ë¶„ê¸°)")

    available_months = get_available_months()
    if len(available_months) < 2:
        st.warning("ìµœê·¼/ì§ì „ ë¶„ê¸° ë¹„êµë¥¼ ìœ„í•´ ìµœì†Œ 2ê°œ ë¶„ê¸° ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        latest_month = available_months[0]
        previous_month = available_months[1]
        st.markdown(f"**ë¹„êµ ê¸°ì¤€**: ìµœê·¼ `{latest_month}` vs ì§ì „ `{previous_month}`")

        current_df, _ = load_company_solvency_data(latest_month)
        previous_df, _ = load_company_solvency_data(previous_month)

        if current_df.empty or previous_df.empty:
            st.warning("ë¹„êµì— í•„ìš”í•œ íšŒì‚¬ë³„ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë°ì´í„° ìˆ˜ì§‘ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        else:
            current_df = apply_sector_reclassification(current_df)
            previous_df = apply_sector_reclassification(previous_df)
            change_df = build_company_change_df(current_df, previous_df)

            if change_df.empty:
                st.warning("ë‘ ë¶„ê¸° ëª¨ë‘ ì¡´ì¬í•˜ëŠ” íšŒì‚¬ ë°ì´í„°ê°€ ì—†ì–´ ë³€ë™ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                change_df['english_name'] = change_df['company_name'].map(get_english_company_name).fillna("")
                before_filter_count = len(change_df)
                change_df = change_df[change_df['english_name'].astype(str).str.strip() != ""].copy()
                filtered_out = before_filter_count - len(change_df)

                if change_df.empty:
                    st.warning("ì˜ë¬¸ íšŒì‚¬ëª…ì´ ìˆëŠ” íšŒì‚¬ê°€ ì—†ì–´ ì°¨íŠ¸ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    if filtered_out > 0:
                        st.caption(f"ì˜ë¬¸ íšŒì‚¬ëª…ì´ ì—†ëŠ” íšŒì‚¬ {filtered_out}ê°œëŠ” ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤.")

                    sector_order = ['ìƒëª…ë³´í—˜', 'ì†í•´ë³´í—˜', 'ì¬ë³´í—˜']

                    row1_cols = st.columns(3)
                    for idx, sector in enumerate(sector_order):
                        with row1_cols[idx]:
                            render_company_change_chart(
                                change_df,
                                sector,
                                'delta_before',
                                f"{sector} - ê²½ê³¼ì¡°ì¹˜ ë°˜ì˜ ì „ ì¦ê°",
                                f"{sector}_before"
                            )

                    row2_cols = st.columns(3)
                    for idx, sector in enumerate(sector_order):
                        with row2_cols[idx]:
                            render_company_change_chart(
                                change_df,
                                sector,
                                'delta_after',
                                f"{sector} - ê²½ê³¼ì¡°ì¹˜ ë°˜ì˜ í›„ ì¦ê°",
                                f"{sector}_after"
                            )

                with st.expander("ìƒì„¸ ë°ì´í„° í™•ì¸"):
                    detail_df = change_df[[
                        'sector', 'company_name', 'english_name',
                        'ratio_before_previous', 'ratio_before_current', 'delta_before',
                        'ratio_after_previous', 'ratio_after_current', 'delta_after'
                    ]].copy()
                    detail_df['delta_before'] = detail_df['delta_before'].round(1)
                    detail_df['delta_after'] = detail_df['delta_after'].round(1)
                    st.dataframe(
                        detail_df.sort_values(['sector', 'delta_after'], ascending=[True, False]),
                        width="stretch"
                    )

elif selected_tab == "ğŸ“¡ ë°ì´í„° ìˆ˜ì§‘ê¸° (Collector)":
    st.subheader("ğŸ“¡ FSS Open API ë°ì´í„° ìˆ˜ì§‘")
    
    # ì„¤ì • ì„¹ì…˜ (ê¸°ì¡´ ì‚¬ì´ë“œë°”ì—ì„œ ì´ë™)
    with st.expander("âš™ï¸ ìˆ˜ì§‘ ì„¤ì • (Settings)", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            if not st.secrets.get("FSS_API_KEY"):
                API_KEY = st.text_input(
                    "ê¸ˆìœµê°ë…ì› API Key", 
                    value=API_KEY,
                    type="password",
                    help="ì¸ì¦í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
                )
            else:
                st.success("âœ… API Keyê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                API_KEY = st.secrets.get("FSS_API_KEY")
        
        with col2:
            TARGET_MONTH = st.text_input(
                "ìˆ˜ì§‘ ê¸°ì¤€ë…„ì›” (YYYYMM)", 
                value="202509",
                help="ì¡°íšŒí•˜ê³  ì‹¶ì€ ë…„ì›”ì„ ì…ë ¥í•˜ì„¸ìš”."
            )

    st.markdown(f"""
    Open APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë³´í—˜ì‚¬ì˜ ì§€ê¸‰ì—¬ë ¥ë¹„ìœ¨ ê´€ë ¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  MotherDuckì— ì €ì¥í•©ë‹ˆë‹¤.
    - **ëŒ€ìƒ**: ìƒëª…ë³´í—˜(H), ì†í•´ë³´í—˜(I)
    """)
    
    # ì‹¤í–‰ ë²„íŠ¼
    if st.button("ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (Start Collection)", type="primary"):
        if not API_KEY:
            st.error("API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥ ê°€ëŠ¥)")
        else:
            # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
            raw_data = asyncio.run(run_async_collection())

            if raw_data:
                df = pd.DataFrame(raw_data)
                
                # ì „ì²˜ë¦¬
                df['ê°’'] = pd.to_numeric(df['ê°’'].astype(str).str.replace(',', ''), errors='coerce')

                # í”¼ë²— í…Œì´ë¸”
                df_pivot = df.pivot_table(
                    index=['êµ¬ë¶„', 'íšŒì‚¬ëª…', 'ê¸°ì¤€ë…„ì›”'],
                    columns='ê³„ì •ëª…',
                    values='ê°’',
                    aggfunc='first'
                ).reset_index()

                # ê²°ê³¼ ì„¹ì…˜
                st.divider()
                st.success(f"âœ… {TARGET_MONTH} ë°ì´í„° ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                tab_res1, tab_res2 = st.tabs(["ğŸ“‹ ìš”ì•½ í…Œì´ë¸” (Pivot)", "ğŸ“„ RAW ë°ì´í„°"])
                
                with tab_res1:
                    st.subheader(f"{TARGET_MONTH} ìˆ˜ì§‘ ê²°ê³¼ (ìš”ì•½)")
                    st.dataframe(df_pivot, width="stretch")
                    
                    # CSV ë‹¤ìš´ë¡œë“œ
                    csv = df_pivot.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ğŸ’¾ ìˆ˜ì§‘ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                        data=csv,
                        file_name=f"insurance_solvency_{TARGET_MONTH}_result.csv",
                        mime="text/csv"
                    )

                with tab_res2:
                    st.subheader(f"{TARGET_MONTH} RAW ë°ì´í„°")
                    st.dataframe(df, width="stretch")
                
                # ìˆ˜ì§‘ì´ ì™„ë£Œë˜ì—ˆìœ¼ë‹ˆ í™”ë©´ ê°±ì‹ ì„ ìœ ë„í•˜ê±°ë‚˜ ì •ë³´ë¥¼ ì œê³µ
                st.info("ğŸ’¡ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. 'ë¶„ì„ ëŒ€ì‹œë³´ë“œ' íƒ­ìœ¼ë¡œ ì´ë™í•˜ì—¬ ì°¨íŠ¸ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.")
            else:
                st.warning("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. API Keyë‚˜ ê¸°ì¤€ë…„ì›”ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
